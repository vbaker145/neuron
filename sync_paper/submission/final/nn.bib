@article{Tumulty2019,
author = {Tumulty, Joseph S. and Cruz, Luis},
doi = {10.1016/j.bpj.2018.11.3003},
file = {:home/vbaker/neuron/lit/JSTumulty_OralQualPaper.pdf:pdf},
issn = {00063495},
journal = {Biophysical Journal},
number = {3},
pages = {558a},
title = {{Effect of Columnar Neural Grouping on Network Synchronization}},
volume = {116},
year = {2019}
}
@article{Folias2012,
abstract = {Persistent activity has been identified as a neural correlate of working memory [J. M. Fuster and G. E. Alexander, Science, 173 (1971), pp. 652-654; S. Funahashi, C. J. Bruce, and P. S. Goldman-Rakic, J. Neurophysiol., 61 (1989), pp. 331-349; P. S. Goldman-Rakic, Neuron, 14 (1995), pp. 477-485]. In neural field theory, stationary bumps are localized states of neural activity that have been used to model this persistent activity. In [S. E. Folias and G. B. Ermentrout, Phys. Rev. Lett., 107 (2011), 228103], we proposed that the persistent activity may be modeled by interacting neural field layers which support persistent activity when each layer in isolation cannot. In this paper, we study the existence, linear stability, and bifurcations of various stationary bumps in a pair of Amari neural fields and in a pair of excitatory-inhibitory (E-I) neural fields on one-dimensional spatial domains. Both support stationary bumps composed of a bump in each layer with (i) identical profiles, (ii) identical centers but different profiles, and (iii) spatially offset centers, and we identify a direct relationship between the two models through the spatial structure of the eigenfunctions for the linearization of the neural field equations about a specific type of stationary bump. Traveling bumps, breathers, and other spatiotemporal phenomena are also found. {\textcopyright} 2012 Society for Industrial and Applied Mathematics.},
author = {Folias, Stefanos E. and Ermentrout, G. Bard},
doi = {10.1137/110860094},
file = {:home/vbaker/neuron/lit/Bifurcations of stationary solutions in an interacting pair of E-I neural fields.pdf:pdf},
issn = {15360040},
journal = {SIAM Journal on Applied Dynamical Systems},
keywords = {Neural field equations,Pattern formation,Stationary bumps,Wilson-Cowan equations},
month = {aug},
number = {3},
pages = {895--938},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Bifurcations of stationary solutions in an interacting pair of E-I neural fields}},
volume = {11},
year = {2012}
}
@article{Holland2001,
author = {Holland, Karen},
doi = {10.1054/nepr.2001.0035},
file = {:home/vbaker/neuron/lit/ML/EchoStatesTechRep.pdf:pdf},
issn = {14715953},
journal = {Nurse Education in Practice},
number = {4},
pages = {221--223},
pmid = {19036266},
title = {{Report from Nurse Education tomorrow 2001: 12th Annual International Participative Conference - For education in health Care, Grey College, University of Durham, UK. 7-9 September 2001}},
volume = {1},
year = {2001}
}
@article{Deneve2017,
abstract = {Understanding how the brain learns to compute functions reliably, efficiently, and robustly with noisy spiking activity is a fundamental challenge in neuroscience. Most sensory and motor tasks can be described as dynamical systems and could presumably be learned by adjusting connection weights in a recurrent biological neural network. However, this is greatly complicated by the credit assignment problem for learning in recurrent networks, e.g., the contribution of each connection to the global output error cannot be determined based only on locally accessible quantities to the synapse. Combining tools from adaptive control theory and efficient coding theories, we propose that neural circuits can indeed learn complex dynamic tasks with local synaptic plasticity rules as long as they associate two experimentally established neural mechanisms. First, they should receive top-down feedbacks driving both their activity and their synaptic plasticity. Second, inhibitory interneurons should maintain a tight balance between excitation and inhibition in the circuit. The resulting networks could learn arbitrary dynamical systems and produce irregular spike trains as variable as those observed experimentally. Yet, this variability in single neurons may hide an extremely efficient and robust computation at the population level.},
archivePrefix = {arXiv},
arxivId = {1705.08031},
author = {Den{\`{e}}ve, Sophie and Alemi, Alireza and Bourdoukan, Ralph},
doi = {10.1016/j.neuron.2017.05.016},
eprint = {1705.08031},
file = {:home/vbaker/neuron/lit/The brain as an efficient and robust adaptive learner.pdf:pdf},
issn = {10974199},
journal = {Neuron},
keywords = {adaptive control,balanced excitation/inhibition,efficient coding,error feedback,learning,prediction errors,recurrent networks,robustness,spike coding},
number = {5},
pages = {969--977},
pmid = {28595053},
title = {{The Brain as an Efficient and Robust Adaptive Learner}},
volume = {94},
year = {2017}
}
@article{Su2011,
abstract = {A Low power g m-boosted differential Colpitts voltage-controlled oscillator (VCO) using current-reused technique is presented. With the proposed g m-boosted and current-reused technique, the power consumption of the VCO is decreased. In addition, the superior cyclostationary noise property of the Colpitts VCO can be used to improve the phase noise. The proposed VCO is implemented in 0.18m CMOS 1P6M process. The core VCO only dissipates 1.05 mW with 1V supply. At 5.255 GHz, the measurements show 117.62 dBc/Hz phase noise at 1 MHz offset. {\textcopyright} 2011 IEEE.},
author = {Su, Yi Pei and Hu, Wei Yi and Lin, Jia Wei and Chen, Yun Chung and Sezer, Sakir and Chen, Sao Jie},
doi = {10.1109/SOCC.2011.6085109},
file = {:home/vbaker/neuron/lit/bio/Receptive fields of single neurones in the cat striate cortex.pdf:pdf},
isbn = {9781457716164},
issn = {21641676},
journal = {International System on Chip Conference},
pages = {247--250},
title = {{Low power Gm-boosted differential Colpitts VCO}},
year = {2011}
}
@article{Auer2002,
abstract = {A learning algorithm is presented for circuits consisting of a single layer of perceptrons. We refer to such circuits as parallel perceptrons. In spite of their simplicity, these circuits are universal approximators for arbitrary boolean and continuous functions. In contrast to backprop for multi-layer perceptrons, our new learning algorithm - the parallel delta rule (p-delta rule) - only has to tune a single layer of weights, and it does not require the computation and communication of analog values with high precision. Reduced communication also distinguishes our new learning rule from other learning rules for such circuits such as those traditionally used for MADALINE. A theoretical analysis shows that the p-delta rule does in fact implement gradient descent - with regard to a suitable error measure - although it does not require to compute derivatives. Furthermore it is shown through experiments on common real-world benchmark datasets that its performance is competitive with that of other learning approaches from neural networks and machine learning. Thus our algorithm also provides an interesting new hypothesis for the organization of learning in biological neural systems. {\textcopyright} Springer-VerlagBerlin Heidelberg2002.},
author = {Auer, Peter and Burgsteiner, Harald and Maass, Wolfgang},
doi = {10.1007/3-540-46084-5_21},
file = {:home/vbaker/neuron/lit/ML/The p-Delta learning rule for parallel perceptrons.pdf:pdf},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {8556},
pages = {123--128},
title = {{Reducing communication for distributed learning in neural networks}},
volume = {2415},
year = {2002}
}
@article{Ferezou2006,
abstract = {Voltage-sensitive dye imaging resolves the spatiotemporal dynamics of supragranular subthreshold cortical activity with millisecond temporal resolution and subcolumnar spatial resolution. We used a flexible fiber optic image bundle to visualize voltage-sensitive dye dynamics in the barrel cortex of freely moving mice while simultaneously filming whisker-related behavior to generate two movies matched frame-by-frame with a temporal resolution of up to 2 ms. Sensory responses evoked by passive whisker stimulation lasted longer and spread further across the barrel cortex in awake mice compared to anesthetized mice. Passively evoked sensory responses were large during behaviorally quiet periods and small during active whisking. However, as an exploring mouse approached an object while whisking, large-amplitude, propagating cortical sensory activity was evoked by active whisker-touch. These experiments demonstrate that fiber optics can be used to image cortical sensory activity with high resolution in freely moving animals. The results demonstrate differential processing of sensory input depending upon behavior. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Ferezou, Isabelle and Bolea, Sonia and Petersen, Carl C.H.},
doi = {10.1016/j.neuron.2006.03.043},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferezou, Bolea, Petersen - 2006 - Visualizing the Cortical Representation of Whisker Touch Voltage-Sensitive Dye Imaging in Freely Movin.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
month = {may},
number = {4},
pages = {617--629},
pmid = {16701211},
publisher = {Elsevier},
title = {{Visualizing the Cortical Representation of Whisker Touch: Voltage-Sensitive Dye Imaging in Freely Moving Mice}},
url = {http://www.cell.com/article/S0896627306002704/fulltext http://www.cell.com/article/S0896627306002704/abstract https://www.cell.com/neuron/abstract/S0896-6273(06)00270-4},
volume = {50},
year = {2006}
}
@misc{Pitkow2017,
abstract = {It is widely believed that the brain performs approximate probabilistic inference to estimate causal variables in the world from ambiguous sensory data. To understand these computations, we need to analyze how information is represented and transformed by the actions of nonlinear recurrent neural networks. We propose that these probabilistic computations function by a message-passing algorithm operating at the level of redundant neural populations. To explain this framework, we review its underlying concepts, including graphical models, sufficient statistics, and message-passing, and then describe how these concepts could be implemented by recurrently connected probabilistic population codes. The relevant information flow in these networks will be most interpretable at the population level, particularly for redundant neural codes. We therefore outline a general approach to identify the essential features of a neural message-passing algorithm. Finally, we argue that to reveal the most important aspects of these neural computations, we must study large-scale activity patterns during moderately complex, naturalistic behaviors.},
author = {Pitkow, Xaq and Angelaki, Dora E.},
booktitle = {Neuron},
doi = {10.1016/j.neuron.2017.05.028},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pitkow, Angelaki - 2017 - Inference in the Brain Statistics Flowing in Redundant Population Codes.pdf:pdf},
issn = {10974199},
keywords = {brain,coding,inference,message-passing,nonlinear,nuisance,population code,redundant,theory},
month = {jun},
number = {5},
pages = {943--953},
pmid = {28595050},
publisher = {Cell Press},
title = {{Inference in the Brain: Statistics Flowing in Redundant Population Codes}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.05.028},
volume = {94},
year = {2017}
}
@article{ascoli2010,
abstract = {Postinhibitory rebound spiking is characteristic of several neuron types and brain regions, where it sustains spontaneous activity and central pattern generation. However, rebound spikes are rarely observed in the principal cells of the hippocampus under physiological conditions. Were port that CA1 pyramidal neurons support rebound spikes mediated by hyperpolarization-activated inward current (Ih ), and normally masked by A-type potassium channels (KA). In both experiments and computational models, KA blockage or reduction consistently resulted in a somatic action potential upon release from hyperpolarizing injections in the soma or main apical dendrite. Rebound spiking was systematically abolished by the additional blockage or reduction of Ih. Since the density of both KA and I h increases in these cells with the distance from the soma, such "latent" mechanism may be most effective in the distal dendrites, which are targeted by a variety of GABAergic interneurons. Detailed computer simulations, validated against the experimental data, demonstrate that rebound spiking can result from activation of distal inhibitory synapses. In particular, partial KA reduction confined to one or few branches of the apical tuft may be sufficient to elicit a local spike following a train of synaptic inhibition. Moreover, the spatial extent and amount of KA reduction determines whether the dendritic spike propagates to the soma. These data suggest that the plastic regulation of KA can provide a dynamic switch to unmask postinhibitory spiking in CA1 pyramidal neurons. This newly discovered local modulation of postinhibitory spiking further increases the signal processing power of the CA1 synaptic microcircuitry. Copyright {\textcopyright} 2010 the authors.},
author = {Ascoli, Giorgio A. and Gasparini, Sonia and Medinilla, Virginia and Migliore, Michele},
doi = {10.1523/JNEUROSCI.4066-09.2010},
file = {:home/vbaker/neuron/lit/Local Control of Postinhibitory Rebound Spiking in CA1 Pyramidal Neuron Dendrites.pdf:pdf},
issn = {02706474},
journal = {Journal of Neuroscience},
number = {18},
pages = {6434--6442},
pmid = {20445069},
title = {{Local control of postinhibitory rebound spiking in CA1 pyramidal neuron dendrites}},
volume = {30},
year = {2010}
}
@article{gibson2009,
abstract = {Inhibitory interneurons are critical to sensory transformations plasticity and synchronous activity in the neocortex. There are many types of inhibitory neurons, but their synaptic organization is poorly understood. Here we describe two functionally distinct inhibitory networks comprising either fast-spiking (FS) or low-threshold spiking (LTS) neurons. Paired-cell recordings showed that inhibitory neurons of the same type were strongly interconnected by electrical synapses, but electrical synapses between different inhibitory cell types were rare. The electrical synapses were strong enough to synchronize spikes in coupled interneurons. Inhibitory chemical synapses were also common between FS cells, and between FS and LTS cells, but LTS cells rarely inhibited one another. Thalamocortical synapses, which convey sensory information to the cortex, specifically and strongly excited only the FS cell network. The electrical and chemical synaptic connections of different types of inhibitory neurons are specific, and may allow each inhibitory network to function independently.},
author = {Gibson, Jay R. and Belerlein, Michael and Connors, Barry W.},
doi = {10.1038/47035},
file = {:home/vbaker/neuron/lit/Two networks of electrically coupled inhibitory neurons in neocortex.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {6757},
pages = {75--79},
pmid = {10573419},
title = {{Two networks of electrically coupled inhibitory neurons in neocortex}},
volume = {402},
year = {1999}
}
@article{Dayan2005,
abstract = {We have thus far considered discriminating between two quite distinct stimulus values, plus and minus. Often we are interested in discriminating between two stimulus values s + s and s that are very close to one another. In this case, the likelihood ratio is p[r|s + s] p[r|s] ≈ p[r|s] + s∂p[r|s]/∂s p[r|s] = 1 + s ∂ ln p[r|s] ∂s. (3.18) For small s, a test that compares Z(r) = ∂ ln p[r|s] ∂s (3.19) to a threshold (z − 1)//s is equivalent to the likelihood ratio test. The function Z(r) is sometimes called the score. score Z(r) 3.3 Population Decoding The use of large numbers of neurons to represent information is a basic operating principle of many nervous systems. Population coding has a number of advantages, including reduction of uncertainty due to neuronal variability and the ability to represent a number of different stimulus attributes simultaneously. Individual neurons in such a population typically have different but overlapping selectivities, so that many neurons, but not necessarily all, respond to a given stimulus. In the previous section, we discussed discrimination between stimuli on the basis of the response of a single neuron. The responses of a population of neurons can also be used for discrimination, with the only essential difference being that terms such as p[r|s] are replaced by p[r|s], the conditional probability density of the population response r. ROC analysis, likelihood ratio tests, and the Neyman-Pearson lemma continue to apply in exactly the same way. Discrimination is a special case of decoding in which only a few different stimulus values are considered. A more general problem is the extraction of a continuous stimulus parameter from one or more neuronal responses. In this section, we study how the value of a continuous parameter associated with a static stimulus can be decoded from the spike-count firing rates of a population of neurons. The cercal system of the cricket, which senses the direction of incoming air currents as a warning of approaching predators, is an interesting example of population coding involving a relatively small number of neurons. Crickets and related insects have two appendages called cerci extending},
author = {Dayan, Peter and Abbott, Larry F},
file = {:home/vbaker/neuron/lit/dayan_abbott.pdf:pdf},
journal = {Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems},
pages = {101--108},
title = {{Optimal Decoding Methods}},
url = {http://www.math.pitt.edu/$\sim$bdoiron/assets/dayan_abbott.pdf},
year = {2005}
}
@article{maass2002,
abstract = {A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.},
author = {Maass, Wolfgang and Natschl{\"{a}}ger, Thomas and Markram, Henry},
doi = {10.1162/089976602760407955},
file = {:home/vbaker/neuron/lit/Real-Time Computing Without Stable States A New Framework For Neural Computation.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {11},
pages = {2531--2560},
pmid = {12433288},
title = {{Real-time computing without stable states: A new framework for neural computation based on perturbations}},
volume = {14},
year = {2002}
}
@article{Kreuz2011,
abstract = {A wide variety of approaches to estimate the degree of synchrony between two or more spike trains have been proposed. One of the most recent methods is the ISI-distance which extracts information from the interspike intervals (ISIs) by evaluating the ratio of the instantaneous firing rates. In contrast to most previously proposed measures it is parameter free and time-scale independent. However, it is not well suited to track changes in synchrony that are based on spike coincidences. Here we propose the SPIKE-distance, a complementary measure which is sensitive to spike coincidences but still shares the fundamental advantages of the ISI-distance. In particular, it is easy to visualize in a time-resolved manner and can be extended to a method that is also applicable to larger sets of spike trains. We show the merit of the SPIKE-distance using both simulated and real data. {\textcopyright} 2010 Elsevier B.V.},
author = {Kreuz, Thomas and Chicharro, Daniel and Greschner, Martin and Andrzejak, Ralph G.},
doi = {10.1016/j.jneumeth.2010.11.020},
file = {:home/vbaker/neuron/lit/Time resolved and time scale adaptive measures of spike train synchrony.pdf:pdf},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
keywords = {Clustering,Neuronal coding,Spike trains,Synchronization,Time series analysis},
number = {1},
pages = {92--106},
pmid = {21129402},
publisher = {Elsevier B.V.},
title = {{Time-resolved and time-scale adaptive measures of spike train synchrony}},
url = {http://dx.doi.org/10.1016/j.jneumeth.2010.11.020},
volume = {195},
year = {2011}
}
@article{Oscillators1986,
author = {Oscillators, Coupled},
file = {:home/vbaker/neuron/lit/Symmetry and phaselocking in chains of weakly coupled oscillators.pdf:pdf},
title = {{Symmetry and Phaselocking}},
volume = {XXXIX},
year = {1986}
}
@article{Steil2007,
abstract = {The so called MSO-problem, - a simple superposition of two or more sinusoidal waves -, has recently been discussed as a benchmark problem for reservoir computing and was shown to be not learnable by standard echo state regression. However, we show that are at least three simple ways to learn the MSO signal by introducing a time window on the input, by changing the network time step to match the sampling rate of the signal, and by reservoir adaptation. The latter approach is based on an universal principle to implement a sparsity constraint on the network activity patterns which improves spatio-temporal encoding in the network.},
author = {Steil, J. J.},
file = {:home/vbaker/neuron/lit/ML/Several_Ways_to_Solve_the_MSO_Problem.pdf:pdf},
isbn = {2930307099},
journal = {ESANN 2007 Proceedings - 15th European Symposium on Artificial Neural Networks},
number = {April},
pages = {489--494},
title = {{Several ways to solve the MSO problem}},
year = {2007}
}
@article{Esman2017,
abstract = {Signals arising in nearly all disciplines, including telecommunications, mechanics, biology, astronomy, and nature are generally modulated, carrying corresponding signatures in both the temporal and spectral domains. This fact was long recognized by cyclostationary and cumulant analysis, providing qualitatively better means to separate stochastic from deterministically modulated radiation. In contrast to simple spectral analysis, the cyclostationary technique provides a high level of spectral discrimination, allowing for considerable signal selectivity even in the presence of high levels of background noise and interference. When performed with sufficient resolution, cyclostationary analysis also provides the ability for signal analysis and classification. Unfortunately, these advantages come at a cost of large computational complexity posing fundamental detection challenges. In the case of modern ultrawideband signals, the requirements for persistent cyclostationary analysis are considerably beyond the processing complexity of conventional electronics. Recognizing this limit, we report a new photonically assisted cyclostationary analyzer that eliminates the need for high-bandwidth digitization and real-time Fourier processors. The new receiver relies on mutually coherent frequency combs used to generate a Fourier representation of the received signal in a computation-free manner. With the advent of practical, cavity-free optical frequency combs, the complexity for cyclostationary analysis can be greatly reduced, paving a path toward persistent wideband cyclostationary analysis in an ultrawideband operating regime.},
author = {Esman, Daniel J. and Ataie, Vahid and Kuo, Bill Ping Piu and Temprana, Eduardo and Alic, Nikola and Radic, Stojan},
doi = {10.1109/JLT.2017.2715336},
file = {:home/vbaker/neuron/lit/photonic/Comb-Assisted Cyclostationary Analysis of Wideband RF Signals.pdf:pdf},
issn = {15582213},
journal = {Journal of Lightwave Technology},
keywords = {Cyclostationary receiver,frequency combs,noise discrimination,spectral analysis},
number = {17},
pages = {3705--3712},
title = {{Comb-Assisted Cyclostationary Analysis of Wideband RF Signals}},
volume = {35},
year = {2017}
}
@article{Lukosevicius2009,
abstract = {Echo State Networks and Liquid State Machines introduced a new paradigm in artificial recurrent neural network (RNN) training, where an RNN (the reservoir) is generated randomly and only a readout is trained. The paradigm, becoming known as reservoir computing, greatly facilitated the practical application of RNNs and outperformed classical fully trained RNNs in many tasks. It has lately become a vivid research field with numerous extensions of the basic idea, including reservoir adaptation, thus broadening the initial paradigm to using different methods for training the reservoir and the readout. This review systematically surveys both current ways of generating/adapting the reservoirs and training different types of readouts. It offers a natural conceptual classification of the techniques, which transcends boundaries of the current "brand-names" of reservoir methods, and thus aims to help in unifying the field and providing the reader with a detailed "map" of it. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Luko{\v{s}}evi{\v{c}}ius, Mantas and Jaeger, Herbert},
doi = {10.1016/j.cosrev.2009.03.005},
file = {:home/vbaker/neuron/lit/ML/Resevoir_Computing_Approaches_to_Recurrent_Neural_Network_Training.pdf:pdf},
issn = {15740137},
journal = {Computer Science Review},
number = {3},
pages = {127--149},
title = {{Reservoir computing approaches to recurrent neural network training}},
volume = {3},
year = {2009}
}
@article{Salehi2014,
abstract = {As a new approach to recognition and classification problems, photonic reservoir computing has such advantages as parallel information processing, power efficient and high speed. In this paper, a photonic structure has been proposed for reservoir computing which is investigated using a simple, yet, non-partial noisy time series prediction task. This study includes the application of a suitable topology with self-feedbacks in a network of SOAs - which lends the system a strong memory - and leads to adjusting adequate parameters resulting in perfect recognition accuracy (100%) for noise-free time series, which shows a 3% improvement over previous results. For the classification of noisy time series, the rate of accuracy showed a 4% increase and amounted to 96%. Furthermore, an analytical approach was suggested to solve rate equations which led to a substantial decrease in the simulation time, which is an important parameter in classification of large signals such as speech recognition, and better results came up compared with previous works. {\textcopyright} 2014 {\textcopyright} 2014 Taylor & Francis.},
author = {Salehi, Mohammad Reza and Dehyadegari, Louiza},
doi = {10.1080/09500340.2014.940017},
file = {:home/vbaker/neuron/lit/photonic/Toward optical signal processing using photonic reservoir computing.pdf:pdf},
issn = {13623044},
journal = {Journal of Modern Optics},
keywords = {analytical method,noisy time series classification,photonic reservoir computing,semiconductor optical amplifiers},
number = {17},
pages = {1442--1451},
title = {{Optical signal processing using photonic reservoir computing}},
volume = {61},
year = {2014}
}
@article{mountcastle1997,
abstract = {The modular organization of nervous systems is a widely documented principle of design for both vertebrate and invertebrate brains of which the columnar organization of the neocortex is an example. The classical cytoarchitectural areas of the neocortex are composed of smaller units, local neural circuits repeated iteratively within each area. Modules may vary in cell type and number, in internal and external connectivity, and in mode of neuronal processing between different large entities; within any single large entity they have a basic similarity of internal design and operation. Modules are most commonly grouped into entities by sets of dominating external connections. This unifying factor is most obvious for the heterotypical sensory and motor areas of the neocortex. Columnar defining factors in homotypical areas are generated, in part, within the cortex itself. The set of all modules composing such an entity may be fractionated into different modular subsets by different extrinsic connections. Linkages between them and subsets in other large entities form distributed systems. The neighbourhood relations between connected subsets of modules in different entities result in nested distributed systems that serve distributed functions. A cortical area defined in classical cytoarchitectural terms may belong to more than one and sometimes to several distributed systems. Columns in cytoarchitectural areas located at some distance from one another but with some common properties, may be linked by long-range, intracortical connections.},
author = {Mountcastle, Vernon B.},
doi = {10.1093/brain/120.4.701},
file = {:home/vbaker/neuron/lit/bio/The columnar organization of the neocortex.pdf:pdf},
issn = {00068950},
journal = {Brain},
keywords = {Columnar organization,Distributed systems,Modules,Neocortex,Primates},
number = {4},
pages = {701--722},
pmid = {9153131},
title = {{The columnar organization of the neocortex}},
volume = {120},
year = {1997}
}
@article{reimer2010,
abstract = {Central processing of acoustic signals is assumed to take place in a stereotypical spatial and temporal pattern involving different fields of auditory cortex. So far, cortical propagating waves representing such patterns have mainly been demonstrated by optical imaging, repeatedly in the visual and somatosensory cortex. In this study, the surface of rat auditory cortex was mapped by recording local field potentials (LFPs) in response to a broadband acoustic stimulus. From the peak amplitudes of LFPs, cortical activation maps were constructed over 4 cortical auditory fields. Whereas response onset had same latencies across primary auditory field (A1), anterior auditory field (AAF), and ventral auditory field and longer latencies in posterior auditory field, activation maps revealed a reproducible wavelike pattern of activity propagating for ∼45 ms poststimulus through all cortical fields. The movement observed started with 2 waves within the primary auditory fields A1 and AAF moving from ventral to dorsal followed by a motion from rostral to caudal, passing continuously through higher-order fields. The pattern of propagating waves was well reproducible and showed only minor changes if different anesthetics were used. The results question the classical " hierarchical" model of cortical areas and demonstrate that the different fields process incoming information as a functional unit. {\textcopyright} The Author 2010. Published by Oxford University Press.},
author = {Reimer, Antonia and Hubka, Peter and Engel, Andreas K. and Kral, Andrej},
doi = {10.1093/cercor/bhq073},
file = {:home/vbaker/neuron/lit/Fast Propagating Waves within the Rodent Auditory Cortex.pdf:pdf},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {Anesthesia,Cortical hierarchy,Cortical organization,Spatiotemporal pattern,Traveling wave},
number = {1},
pages = {166--177},
pmid = {20444841},
title = {{Fast propagating waves within the rodent auditory cortex}},
volume = {21},
year = {2011}
}
@article{Tsodyks2000,
abstract = {Throughout the neocortex, groups of neurons have been found to fire synchronously on the time scale of several milliseconds. This near coincident firing of neurons could coordinate the multifaceted information of different features of a stimulus. The mechanisms of generating such synchrony are not clear. We simulated the activity of a population of excitatory and inhibitory neurons randomly interconnected into a recurrent network via synapses that display temporal dynamics in their transmission; surprisingly, we found a behavior of the network where action potential activity spontaneously self-organized to produce highly synchronous bursts involving virtually the entire network. These population bursts were also triggered by stimuli to the network in an all-or-none manner. We found that the particular intensities of the external stimulus to specific neurons were crucial to evoke population bursts. This topographic sensitivity therefore depends on the spectrum of basal discharge rates across the population and not on the anatomical individuality of the neurons, because this was random. These results suggest that networks in which neurons are even randomly interconnected via frequency-dependent synapses could exhibit a novel form of reflex response that is sensitive to the nature of the stimulus as well as the background spontaneous activity.},
author = {Tsodyks, M. and Uziel, A. and Markram, H.},
doi = {10.1523/jneurosci.20-01-j0003.2000},
file = {:home/vbaker/neuron/lit/Synchorny Generation in Recurrent Networks with Frequency-Dependent Synapses.pdf:pdf},
issn = {15292401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {1993,abbott and van vreeswijk,action potential encoding,cortical column,in this state,modeling,neural network,neurons,of asynchronous activity with,spike timing,synaptic plasticity,the,uncorrelated firing of individual},
number = {1},
pages = {1--5},
pmid = {10627627},
title = {{Synchrony generation in recurrent networks with frequency-dependent synapses.}},
volume = {20},
year = {2000}
}
@article{Strogatz1991,
abstract = {We analyze a mean-field model of coupled oscillators with randomly distributed frequencies. This system is known to exhibit a transition to collective oscillations: for small coupling, the system is incoherent, with all the oscillators running at their natural frequencies, but when the coupling exceeds a certain threshold, the system spontaneously synchronizes. We obtain the first rigorous stability results for this model by linearizing the Fokker-Planck equation about the incoherent state. An unexpected result is that the system has pathological stability properties: the incoherent state is unstable above threshold, but neutrally stable below threshold. We also show that the system is singular in the sense that its stability properties are radically altered by infinitesimal noise. {\textcopyright} 1991 Plenum Publishing Corporation.},
author = {Strogatz, Steven H. and Mirollo, Renato E.},
doi = {10.1007/BF01029202},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strogatz, Mirollo - 1991 - Stability of incoherence in a population of coupled oscillators.pdf:pdf},
issn = {00224715},
journal = {Journal of Statistical Physics},
keywords = {Nonlinear oscillator,bifurcation,collective phenomena,mean-field model,phase locking,phase transition,synchronization},
month = {may},
number = {3-4},
pages = {613--635},
publisher = {Kluwer Academic Publishers-Plenum Publishers},
title = {{Stability of incoherence in a population of coupled oscillators}},
url = {https://link.springer.com/article/10.1007/BF01029202},
volume = {63},
year = {1991}
}
@article{Xiang2016,
abstract = {The dynamical response properties of photonic neuron based on vertical-cavity surface emitting lasers (VCSELs) subject to orthogonal polarized optical pulse injection stimuli have been numerically investigated. Based on the well-known spin flip model, we first reproduce some experimental findings of neuron-like dynamics in VCSELs, such as phasic spiking with a single abrupt pulse, and tonic spiking with multiple periodic pulses. Besides, we further go beyond in three directions and obtain several novel results. The operating parameter ranges corresponding to different neuron-like dynamics are identified by extensive bifurcation analysis. In addition, the effect of the time-varying pump current on the neuron-like dynamics for VCSELs under given optical injecting pulse strength is also discussed. For a given pump current, the spiking frequency dependence on the stimuli strength is further revealed in VCSELs with time-varying optical pulse injection. Such controllable neuron-like response dynamics and spiking frequency dependence in VCSELs are interesting and valuable for ultrafast photonic neuromorphic systems and neuron-inspired photonic information processing.},
author = {Xiang, Shuiying and Wen, Aijun and Pan, Wei},
doi = {10.1109/JPHOT.2016.2614104},
file = {:home/vbaker/neuron/lit/Emulation_of_Spiking_Response_and_Spiking_Frequency_Property_in_VCSEL_Photonic_Neuron.pdf:pdf},
issn = {19430655},
journal = {IEEE Photonics Journal},
keywords = {Vertical-cavity surface-emitting lasers (VCSELs),photonic neuron,polarization,spiking frequency dependence.},
number = {5},
title = {{Emulation of spiking response and spiking frequency property in VCSEL-based photonic neuron}},
volume = {8},
year = {2016}
}
@article{Harris2012,
abstract = {Neuronal computation is energetically expensive. Consequently, the brain@s limited energy supply imposes constraints on its information processing capability. Most brain energy is used on synaptic transmission, making it important to understand how energy is provided to and used by synapses. We describe how information transmission through presynaptic terminals and postsynaptic spines is related to their energy consumption, assess which mechanisms normally ensure an adequate supply of ATP to these structures, consider the influence of synaptic plasticity and changing brain state on synaptic energy use, and explain how disruption of the energy supply to synapses leads to neuropathology.},
author = {Harris, Julia J. and Jolivet, Renaud and Attwell, David},
doi = {10.1016/j.neuron.2012.08.019},
file = {:home/vbaker/neuron/lit/bio/Synaptic Energy Use and Supply.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {5},
pages = {762--777},
pmid = {22958818},
publisher = {Elsevier Inc.},
title = {{Synaptic Energy Use and Supply}},
url = {http://dx.doi.org/10.1016/j.neuron.2012.08.019},
volume = {75},
year = {2012}
}
@article{Senk2020,
author = {Senk, Johanna and Korvasov{\'{a}}, Karol and Schuecker, Jannis and Hagen, Espen and Tetzlaff, Tom and Diesmann, Markus and Helias, Moritz},
doi = {10.1103/PhysRevResearch.2.023174},
journal = {Phys. Rev. Research},
month = {may},
number = {2},
pages = {23174},
publisher = {American Physical Society},
title = {{Conditions for wave trains in spiking neural networks}},
url = {https://link.aps.org/doi/10.1103/PhysRevResearch.2.023174},
volume = {2},
year = {2020}
}
@article{Williams1997,
abstract = {Chains of coupled limit-cycle oscillators are considered, in which the coupling is assumed to be weak and only between adjacent oscillators. For such a system the change in frequency of an oscillator due to the coupling can be expressed, up to first order in the coupling strength, by functions that depend only on the phase difference between the coupled oscillators. In this article a numerical algorithm is developed for the evaluation of these functions (the H-functions) in terms of a single oscillator and the interactions between coupled oscillators. The technique is applied to a connectionist model for the locomotor pattern generator in the lamprey spinal cord. An H-function so derived is compared to a function derived empirically (the C-function) from simulations of the same system. The phase lags that develop between adjacent oscillators in a simulated chain are compared with those predicted theoretically, and it is shown that coupling that is functionally 'strong' is nonetheless weak enough to behave as predicted.},
author = {Williams, Thelma L. and Bowtell, Graham},
doi = {10.1023/A:1008864410375},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Bowtell - 1997 - The calculation of frequency-shift functions for chains of coupled oscillators, with application to a network.pdf:pdf},
issn = {09295313},
journal = {Journal of Computational Neuroscience},
keywords = {Central pattern generator,Coupled oscillators,Iamprey spinal cord,Intersegmental coordination,Locomotion},
number = {1},
pages = {47--55},
pmid = {9046451},
publisher = {Kluwer Academic Publishers},
title = {{The calculation of frequency-shift functions for chains of coupled oscillators, with application to a network model of the Iamprey locomotor pattern generator}},
url = {https://link.springer.com/article/10.1023/A:1008864410375},
volume = {4},
year = {1997}
}
@article{Bressloff1997,
abstract = {A one-dimensional array of pulse-coupled integrate-and-fire neurons, each filtering input through an idealized passive dendritic cable, is used to model the nonlinear behavior induced by axodendritic interactions in neural populations. The relative firing phase of the neurons in the array is derived in the weak-coupling regime. It is shown that for long-range excitatory coupling the phases can undergo a bifurcation from a synchronous state to a state of traveling oscillatory waves. We establish the possible role of dendritic structure in the desynchronization of cortical oscillations. {\textcopyright} 1997 The American Physical Society.},
author = {Bressloff, P. C. and Coombes, S.},
doi = {10.1103/PhysRevLett.78.4665},
file = {:home/vbaker/neuron/lit/Synchrony in an array of integrate and fire neurons with dendritic structure.pdf:pdf},
issn = {10797114},
journal = {Physical Review Letters},
number = {24},
pages = {4665--4668},
title = {{Synchrony in an Array of Integrate-and-Fire Neurons with Dendritic Structure}},
volume = {78},
year = {1997}
}
@article{Markram1998,
abstract = {The nature of information stemming from a single neuron and conveyed simultaneously to several hundred target neurons is not known. Triple and quadruple neuron recordings revealed that each synaptic connection established by neocortical pyramidal neurons is potentially unique. Specifically, synaptic connections onto the same morphological class differed in the numbers and dendritic locations of synaptic contacts, their absolute synaptic strengths, as well as their rates of synaptic depression and recovery from depression. The same axon of a pyramidal neuron innervating another pyramidal neuron and an interneuron mediated frequency-dependent depression and facilitation, respectively, during high frequency discharges of presynaptic action potentials, suggesting that the different natures of the target neurons underlie qualitative differences in synaptic properties. Facilitating-type synaptic connections established by three pyramidal neurons of the same class onto a single interneuron, were all qualitatively similar with a combination of facilitation and depression mechanisms. The time courses of facilitation and depression, however, differed for these convergent connections, suggesting that different prepostsynaptic interactions underlie quantitative differences in synaptic properties. Mathematical analysis of the transfer functions of frequency-dependent synapses revealed supralinear, linear, and sub-linear signaling regimes in which mixtures of presynaptic rates, integrals of rates, and derivatives of rates are transferred to targets depending on the precise values of the synaptic parameters and the history of presynaptic action potential activity. Heterogeneity of synaptic transfer functions therefore allows multiple synaptic representations of the same presynaptic action potential train and suggests that these synaptic representations are regulated in a complex manner. It is therefore proposed that differential signaling is a key mechanism in neocortical information processing, which can be regulated by selective synaptic modifications.},
author = {Markram, Henry and Wang, Yun and Tsodyks, Misha},
doi = {10.1073/pnas.95.9.5323},
file = {:home/vbaker/neuron/lit/bio/Differential signaling via the same axon of neocortical pyramidal neurons.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {9},
pages = {5323--5328},
pmid = {9560274},
title = {{Differential signaling via the same axon of neocortical pyramidal neurons}},
volume = {95},
year = {1998}
}
@article{Roxin2005,
abstract = {We study the effect of delays on the dynamics of large networks of neurons. We show that delays give rise to a wealth of bifurcations and to a rich phase diagram, which includes oscillatory bumps, traveling waves, lurching waves, standing waves arising via a period-doubling bifurcation, aperiodic regimes, and regimes of multistability. We study the existence and the stability of the various dynamical patterns analytically and numerically in a simplified rate model as a function of the interaction parameters. The results derived in that framework allow us to understand the origin of the diversity of dynamical states observed in large networks of spiking neurons. {\textcopyright} 2005 The American Physical Society.},
author = {Roxin, Alex and Brunel, Nicolas and Hansel, David},
doi = {10.1103/PhysRevLett.94.238103},
file = {:home/vbaker/neuron/lit/Role of delays in shaping spatiotemporal dynamics of neuronal activity in large networks.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
number = {23},
pages = {1--4},
pmid = {16090506},
title = {{Role of delays in shaping spatiotemporal dynamics of neuronal activity in large networks}},
volume = {94},
year = {2005}
}
@article{Esser2016,
abstract = {Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (/) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii') can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
archivePrefix = {arXiv},
arxivId = {1603.08270},
author = {Esser, Steven K. and Merolla, Paul A. and Arthur, John V. and Cassidy, Andrew S. and Appuswamy, Rathinakumar and Andreopoulos, Alexander and Berg, David J. and McKinstry, Jeffrey L. and Melano, Timothy and Barch, Davis R. and {Di Nolfo}, Carmelo and Datta, Pallab and Amir, Arnon and Taba, Brian and Flickner, Myron D. and Modha, Dharmendra S.},
doi = {10.1073/pnas.1604850113},
eprint = {1603.08270},
file = {:home/vbaker/neuron/lit/ML/Convolutional networks for fast energy efficient neuromorphic computing.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Convolutional network,Neural network,Neuromorphic,Truenorth},
number = {41},
pages = {11441--11446},
title = {{Convolutional networks for fast, energy-efficient neuromorphic computing}},
volume = {113},
year = {2016}
}
@article{Dfiric1991,
author = {Dfiric, F R I and Theunissen, E and Miller, P},
file = {:home/vbaker/neuron/lit/bio/Representation of Sensory Information in the Cricket Cercal Sensory System.pdf:pdf},
journal = {Neurophysiology},
number = {5},
title = {{of System Accuracy and Optimal Tuning-Curve Widths of Four Primary Interneurons}},
volume = {66},
year = {1991}
}
@article{Larger2017,
abstract = {Reservoir computing, originally referred to as an echo state network or a liquid state machine, is a braininspired paradigm for processing temporal information. It involves learning a "read-out" interpretation for nonlinear transients developed by high-dimensional dynamics when the latter is excited by the information signal to be processed. This novel computational paradigm is derived from recurrent neural network and machine learning techniques. It has recently been implemented in photonic hardware for a dynamical system, which opens the path to ultrafast brain-inspired computing. We report on a novel implementation involving an electro-optic phase-delay dynamics designed with off-the-shelf optoelectronic telecom devices, thus providing the targeted wide bandwidth. Computational efficiency is demonstrated experimentally with speech-recognition tasks. State-of-the-art speed performances reach one million words per second, with very low word error rate. Additionally, to record speed processing, our investigations have revealed computing-efficiency improvements through yet-unexplored temporalinformation- processing techniques, such as simultaneous multisample injection and pitched sampling at the read-out compared to information "write-in".},
author = {Larger, Laurent and Bayl{\'{o}}n-Fuentes, Antonio and Martinenghi, Romain and Udaltsov, Vladimir S. and Chembo, Yanne K. and Jacquot, Maxime},
doi = {10.1103/PhysRevX.7.011015},
file = {:home/vbaker/neuron/lit/photonic/High Speed Photonic Resevoir Computing.pdf:pdf},
issn = {21603308},
journal = {Physical Review X},
keywords = {Complex systems,Nonlinear dynamics,Photonics},
number = {1},
pages = {1--14},
title = {{High-speed photonic reservoir computing using a time-delay-based architecture: Million words per second classification}},
volume = {7},
year = {2017}
}
@article{Fino2011,
abstract = {The connectivity diagram of neocortical circuits is still unknown, and there are conflicting data as to whether cortical neurons are wired specifically or not. To investigate the basic structure of cortical microcircuits, we use a two-photon photostimulation technique that enables the systematic mapping of synaptic connections with single-cell resolution. We map the inhibitory connectivity between upper layers somatostatin-positive GABAergic interneurons and pyramidal cells in mouse frontal cortex. Most, and sometimes all, inhibitory neurons are locally connected to every sampled pyramidal cell. This dense inhibitory connectivity is found at both young and mature developmental ages. Inhibitory innervation of neighboring pyramidal cells is similar, regardless of whether they are connected among themselves or not. We conclude that local inhibitory connectivity is promiscuous, does not form subnetworks, and can approach the theoretical limit of a completely connected synaptic matrix. {\textcopyright} 2011 Elsevier Inc.},
author = {Fino, Elodie and Yuste, Rafael},
doi = {10.1016/j.neuron.2011.02.025},
file = {:home/vbaker/neuron/lit/bio/Dense inhibitory connectivity in neocortex.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {6},
pages = {1188--1203},
pmid = {21435562},
title = {{Dense inhibitory connectivity in neocortex}},
volume = {69},
year = {2011}
}
@article{Riehle2013,
abstract = {Grasping an object involves shaping the hand and fingers in relation to the object's physical properties. Following object contact, it also requires a fine adjustment of grasp forces for secure manipulation. Earlier studies suggest that the control of hand shaping and grasp force involve partially segregated motor cortical networks. However, it is still unclear how information originating from these networks is processed and integrated. We addressed this issue by analyzing massively parallel signals from population measures (local field potentials, LFPs) and single neuron spiking activities recorded simultaneously during a delayed reach-to-grasp task, by using a 100 electrode array chronically implanted in monkey motor cortex. Motor cortical LFPs exhibit a large multi-component movement-related potential (MRP) around movement onset. Here, we show that the peak amplitude of each MRP component and its latency with respect to movement onset vary along the cortical surface covered by the array. Using a comparative mapping approach, we suggest that the spatio-temporal structure of the MRP reflects the complex physical properties of the reach-to-grasp movement. In addition, we explored how the spatio-temporal structure of the MRP relates to two other measures of neuronal activity: the temporal profile of single neuron spiking activity at each electrode site and the somatosensory receptive field properties of single neuron activities. We observe that the spatial representations of LFP and spiking activities overlap extensively and relate to the spatial distribution of proximal and distal representations of the upper limb. Altogether, these data show that, in motor cortex, a precise spatio-temporal pattern of activation is involved for the control of reach-to-grasp movements and provide some new insight about the functional organization of motor cortex during reaching and object manipulation. {\textcopyright} 2013 Riehle, Wirtssohn, Gruen and Brochier.},
author = {Riehle, Alexa and Wirtssohn, Sarah and Gr{\"{u}}n, Sonja and Brochier, Thomas},
doi = {10.3389/fncir.2013.00048},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riehle et al. - 2013 - Mapping the spatio-temporal structure of motor cortical LFP and spiking activities during reach-to-grasp movement.pdf:pdf},
issn = {1662-5110},
journal = {Frontiers in Neural Circuits},
keywords = {Cortical map,High-density recordings,LFP,Monkey motor cortex,Spiking activity},
month = {mar},
number = {MAR},
pages = {48},
publisher = {Frontiers},
title = {{Mapping the spatio-temporal structure of motor cortical LFP and spiking activities during reach-to-grasp movements}},
url = {http://journal.frontiersin.org/article/10.3389/fncir.2013.00048/abstract},
volume = {7},
year = {2013}
}
@article{Verstraeten2007,
abstract = {An implementation of the recently proposed concept of the Liquid State Machine using a Spiking Neural Network (SNN) is trained to perform isolated word recognition. We investigate two different speech front ends and different ways of coding the inputs into spike trains. The robustness against noise added to the speech is also briefly researched. It turns out that a biologically realistic configuration of the LSM gives the best result, and that it performs very well for the task of speech recognition.},
author = {Verstraeten, David and Schrauwen, Benjamin and Stroobandt, Dirk},
file = {:home/vbaker/neuron/lit/ML/Isolated word recognition using a liquid state machine.pdf:pdf},
isbn = {2930307056},
journal = {ESANN 2005 Proceedings - 13th European Symposium on Artificial Neural Networks},
number = {April},
pages = {435--440},
title = {{Isolated word recognition using a Liquid State Machine}},
year = {2007}
}
@article{Muller2014,
abstract = {Propagating waves occur in many excitable media and were recently found in neural systems from retina to neocortex. While propagating waves are clearly present under anaesthesia, whether they also appear during awake and conscious states remains unclear. One possibility is that these waves are systematically missed in trial-averaged data, due to variability. Here we present a method for detecting propagating waves in noisy multichannel recordings. Applying this method to single-trial voltage-sensitive dye imaging data, we show that the stimulus-evoked population response in primary visual cortex of the awake monkey propagates as a travelling wave, with consistent dynamics across trials. A network model suggests that this reliability is the hallmark of the horizontal fibre network of superficial cortical layers. Propagating waves with similar properties occur independently in secondary visual cortex, but maintain precise phase relations with the waves in primary visual cortex. These results show that, in response to a visual stimulus, propagating waves are systematically evoked in several visual areas, generating a consistent spatiotemporal frame for further neuronal interactions. {\textcopyright} 2014 Macmillan Publishers Limited. All rights reserved.},
author = {Muller, Lyle and Reynaud, Alexandre and Chavane, Fr{\'{e}}d{\'{e}}ric and Destexhe, Alain},
doi = {10.1038/ncomms4675},
file = {:home/vbaker/neuron/lit/Stimulus-evoked population response in visual cortex of awake monkey is a propagating wave:},
issn = {20411723},
journal = {Nature Communications},
pmid = {24770473},
title = {{The stimulus-evoked population response in visual cortex of awake monkey is a propagating wave}},
volume = {5},
year = {2014}
}
@article{Gardner2006,
abstract = {In this paper, a concise survey of the literature on cyclostationarity is presented and includes an extensive bibliography. The literature in all languages, in which a substantial amount of research has been published, is included. Seminal contributions are identified as such. Citations are classified into 22 categories and listed in chronological order. Both stochastic and nonstochastic approaches for signal analysis are treated. In the former, which is the classical one, signals are modelled as realizations of stochastic processes. In the latter, signals are modelled as single functions of time and statistical functions are defined through infinite-time averages instead of ensemble averages. Applications of cyclostationarity in communications, signal processing, and many other research areas are considered. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Gardner, William A. and Napolitano, Antonio and Paura, Luigi},
doi = {10.1016/j.sigpro.2005.06.016},
file = {:home/vbaker/neuron/lit/ML/Cyclostationarity_Half_a_century_of_research.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Almost-cyclostationary processes,Almost-cyclostationary time series,Bibliography,Cyclostationarity},
number = {4},
pages = {639--697},
title = {{Cyclostationarity: Half a century of research}},
volume = {86},
year = {2006}
}
@article{Grzyb2009,
abstract = {The properties of separation ability and computational efficiency of Liquid State Machines depend on the neural model employed and on the connection density in the liquid column. A simple model of part of mammalians visual system consisting of one hypercolumn was examined. Such a system was stimulated by two different input patterns, and the Euclidean distance, as well as the partial and global entropy of the liquid column responses were calculated. Interesting insights could be drawn regarding the properties of different neural models used in the liquid hypercolumn, and on the effect of connection density on the information representation capability of the system. {\textcopyright} 2009 IEEE.},
author = {Grzyb, Beata J. and Chinellato, Eris and Wojcik, Grzegorz M. and Kaminski, Wieslaw A.},
doi = {10.1109/IJCNN.2009.5178822},
file = {:home/vbaker/neuron/lit/ML/Which model to use for liquid state machine.pdf:pdf},
isbn = {9781424435531},
journal = {Proceedings of the International Joint Conference on Neural Networks},
pages = {1018--1024},
title = {{Which model to use for the Liquid State Machine?}},
year = {2009}
}
@article{Pyle2017,
abstract = {Randomly connected networks of excitatory and inhibitory spiking neurons provide a parsimonious model of neural variability, but are notoriously unreliable for performing computations. We show that this difficulty is overcome by incorporating the well-documented dependence of connection probability on distance. Spatially extended spiking networks exhibit symmetry-breaking bifurcations and generate spatiotemporal patterns that can be trained to perform dynamical computations under a reservoir computing framework.},
archivePrefix = {arXiv},
arxivId = {1611.01557},
author = {Pyle, Ryan and Rosenbaum, Robert},
doi = {10.1103/PhysRevLett.118.018103},
eprint = {1611.01557},
file = {:home/vbaker/neuron/lit/Spatiotemporal Dynamics and Reliable COmputations in Recurrent Spiking Neural Networks.pdf:pdf},
issn = {10797114},
journal = {Physical Review Letters},
number = {1},
pages = {1--5},
pmid = {28106418},
title = {{Spatiotemporal Dynamics and Reliable Computations in Recurrent Spiking Neural Networks}},
volume = {118},
year = {2017}
}
@article{Heitmann2013,
abstract = {Traveling waves of neuronal oscillations have been observed in many cortical regions, including the motor and sensory cortex. Such waves are often modulated in a task-dependent fashion although their precise functional role remains a matter of debate. Here we conjecture that the cortex can utilize the direction and wavelength of traveling waves to encode information. We present a novel neural mechanism by which such information may be decoded by the spatial arrangement of receptors within the dendritic receptor field. In particular, we show how the density distributions of excitatory and inhibitory receptors can combine to act as a spatial filter of wave patterns. The proposed dendritic mechanism ensures that the neuron selectively responds to specific wave patterns, thus constituting a neural basis of pattern decoding. We validate this proposal in the descending motor system, where we model the large receptor fields of the pyramidal tract neurons - the principle outputs of the motor cortex - decoding motor commands encoded in the direction of traveling wave patterns in motor cortex. We use an existing model of field oscillations in motor cortex to investigate how the topology of the pyramidal cell receptor field acts to tune the cells responses to specific oscillatory wave patterns, even when those patterns are highly degraded. The model replicates key findings of the descending motor system during simple motor tasks, including variable interspike intervals and weak corticospinal coherence. By additionally showing how the nature of the wave patterns can be controlled by modulating the topology of local intra-cortical connections, we hence propose a novel integrated neuronal model of encoding and decoding motor commands. {\textcopyright} 2013 Heitmann et al.},
author = {Heitmann, Stewart and Boonstra, Tjeerd and Breakspear, Michael},
doi = {10.1371/journal.pcbi.1003260},
file = {:home/vbaker/neuron/lit/A Dendritic Mechanism for Decoding Traveling Waves - Principles and Applications to Motor Cortex.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {10},
pmid = {24204220},
title = {{A Dendritic Mechanism for Decoding Traveling Waves: Principles and Applications to Motor Cortex}},
volume = {9},
year = {2013}
}
@article{Hopfield2001,
abstract = {A previous paper described a network of simple integrate-and-fire neurons that contained output neurons selective for specific spatiotemporal patterns of inputs: only experimental results were described. We now present the principles behind the operation of this network and discuss how these principles point to a general class of computational operations that can be carried out easily and naturally by networks of spiking neurons. Transient synchrony of the action potentials of a group of neurons is used to signal "recognition" of a space-time pattern across the inputs of those neurons. Appropriate synaptic coupling produces synchrony when the inputs to these neurons are nearly equal, leaving the neurons unsynchronized or only weakly synchronized for other input circumstances. When the input to this system comes from timed past events represented by decaying delay activity, the pattern of synaptic connections can be set such that synchronization occurs only for selected spatiotemporal patterns. We show how the recognition is invariant to uniform time warp and uniform intensity change of the input events. The fundamental recognition event is a transient collective synchronization, representing "many neurons now agree," an event that is then detected easily by a cell with a small time constant. If such synchronization is used in neurobiological computation, its hallmark will be a brief burst of gamma-band electroencephalogram noise when and where such a recognition event or decision occurs.},
author = {Hopfield, J. J. and Brody, Carlos D.},
doi = {10.1073/pnas.98.3.1282},
file = {:home/vbaker/neuron/lit/Transient Synchrony as a Collective Mechanism for Spatiotemporal Integration.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {3},
pages = {1282--1287},
pmid = {11158631},
title = {{What is a moment? Trasient synchrony as a collective mechanism for spatiotemporal integration}},
volume = {98},
year = {2001}
}
@article{Koryakin2012,
abstract = {This paper investigates the interaction between the driving output feedback and the internal reservoir dynamics in echo state networks (ESNs). The interplay is studied experimentally on the multiple superimposed oscillators (MSOs) benchmark. The experimental data reveals a dual effect of the output feedback strength on the network dynamics: it drives the dynamic reservoir but it can also block suitable reservoir dynamics. Moreover, the data shows that the reservoir size crucially co-determines the likelihood of generating an effective ESN. We show that dependent on the complexity of the MSO dynamics somewhat smaller networks can yield better performance. Optimizing the output feedback weight range and the network size is thus crucial for generating an effective ESN. With proper parameter choices, we show that it is possible to generate ESNs that approximate MSOs with several orders of magnitude smaller errors than those previously reported. We conclude that there appears to be still much more potential in ESNs than previously thought and sketch-out some promising future research directions. {\textcopyright} 2012 Elsevier Ltd.},
author = {Koryakin, Danil and Lohmann, Johannes and Butz, Martin V.},
doi = {10.1016/j.neunet.2012.08.008},
file = {:home/vbaker/neuron/lit/ML/Balanced echo state networks.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Dynamic reservoir,Echo state network,Multiple superimposed oscillator,Output feedback,Recurrent neural networks},
pages = {35--45},
pmid = {23037774},
publisher = {Elsevier Ltd},
title = {{Balanced echo state networks}},
url = {http://dx.doi.org/10.1016/j.neunet.2012.08.008},
volume = {36},
year = {2012}
}
@article{Townsend2018,
abstract = {There is growing evidence that population-level brain activity is often organized into propagating waves that are structured in both space and time. Such spatiotemporal patterns have been linked to brain function and observed across multiple recording methodologies and scales. The ability to detect and analyze these patterns is thus essential for understanding the working mechanisms of neural circuits. Here we present a mathematical and computational framework for the identification and analysis of multiple classes of wave patterns in neural population-level recordings. By drawing a conceptual link between spatiotemporal patterns found in the brain and coherent structures such as vortices found in turbulent flows, we introduce velocity vector fields to characterize neural population activity. These vector fields are calculated for both phase and amplitude of oscillatory neural signals by adapting optical flow estimation methods from the field of computer vision. Based on these velocity vector fields, we then introduce order parameters and critical point analysis to detect and characterize a diverse range of propagating wave patterns, including planar waves, sources, sinks, spiral waves, and saddle patterns. We also introduce a novel vector field decomposition method that extracts the dominant spatiotemporal structures in a recording. This enables neural data to be represented by the activity of a small number of independent spatiotemporal modes, providing an alternative to existing dimensionality reduction techniques which separate space and time components. We demonstrate the capabilities of the framework and toolbox with simulated data, local field potentials from marmoset visual cortex and optical voltage recordings from whole mouse cortex, and we show that pattern dynamics are non-random and are modulated by the presence of visual stimuli. These methods are implemented in a MATLAB toolbox, which is freely available under an open-source licensing agreement.},
author = {Townsend, Rory G. and Gong, Pulin},
doi = {10.1371/journal.pcbi.1006643},
file = {:home/vbaker/neuron/lit/detection and analysis of spatiotemporal patterns in brain activity.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {12},
pages = {1--29},
pmid = {30507937},
title = {{Detection and analysis of spatiotemporal patterns in brain activity}},
volume = {14},
year = {2018}
}
@article{Zhu2019,
abstract = {Brief bursts of high-frequency spikes are a common firing pattern of neurons. The cellular mechanisms of bursting and its biological significance remain a matter of debate. Focusing on the energy aspect, this paper proposes a neural energy calculation method based on the Chay model of bursting. The flow of ions across the membrane of the bursting neuron with or without current stimulation and its power which contributes to the change of the transmembrane electrical potential energy are analyzed here in detail. We find that during the depolarization of spikes in bursting this power becomes negative, which was also discovered in previous research with another energy model. We also find that the neuron's energy consumption during bursting is minimal. Especially in the spontaneous state without stimulation, the total energy consumption (2.152 × 10 −7  J) during 30 s of bursting is very similar to the biological energy consumption (2.468 × 10 −7  J) during the generation of a single action potential, as shown in Wang et al. (Neural Plast 2017, 2017a). Our results suggest that this property of low energy consumption could simply be the consequence of the biophysics of generating bursts, which is consistent with the principle of energy minimization. Our results also imply that neural energy plays a critical role in neural coding, which opens a new avenue for research of a central challenge facing neuroscience today.},
author = {Zhu, Fengyun and Wang, Rubin and Pan, Xiaochuan and Zhu, Zhenyu},
doi = {10.1007/s11571-018-9503-3},
file = {:home/vbaker/neuron/lit/bio/Energy expenditure computation of a single bursting neuron.pdf:pdf},
isbn = {1157101895},
issn = {18714099},
journal = {Cognitive Neurodynamics},
keywords = {Bursting,Chay model,Energy coding,Na/K-ATPase pump,Neural energy},
number = {1},
pages = {75--87},
publisher = {Springer Netherlands},
title = {{Energy expenditure computation of a single bursting neuron}},
url = {https://doi.org/10.1007/s11571-018-9503-3},
volume = {13},
year = {2019}
}
@article{Atay2006,
abstract = {We introduce distributed axonal transmission speeds and a long-range constant feedback loop into the standard neural field model. We analyze the stability of spatially homogeneous equilibrium solutions for general connectivity kernels. By studying reduced models based on the assumption of small delays, we determine the effects of the delays on the stability and bifurcations. We show in a reduced model that delayed excitatory feedback generally facilitates stationary bifurcations and Turing patterns, while suppressing the bifurcation of periodic solutions and traveling waves. The reverse conclusion holds for inhibitory feedback. In case of oscillatory bifurcations, the variance of the distributed propagation and feedback delays affects the frequency of periodic solutions and the phase speed of traveling waves. Moreover, we give a nonlinear analysis of traveling fronts and find that distributed transmission speeds can maximize the front speed.},
author = {Atay, Fatihcan M. and Hutt, Axel},
doi = {10.1137/050629367},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Atay, Hutt - 2006 - Neural fields with distributed transmission speeds and long-range feedback delays.pdf:pdf},
issn = {15360040},
journal = {SIAM Journal on Applied Dynamical Systems},
keywords = {Distributed delays,Nonlocal interaction,Spatio-temporal patterns,Synaptic networks,Traveling fronts},
month = {dec},
number = {4},
pages = {670--698},
publisher = {Society for Industrial and Applied Mathematics Publications},
title = {{Neural fields with distributed transmission speeds and long-range feedback delays}},
url = {http://www.siam.org/journals/siads/5-4/62936.html},
volume = {5},
year = {2006}
}
@article{Keane2018,
abstract = {Recent experimental studies show cortical circuit responses to external stimuli display varied dynamical properties. These include stimulus strength-dependent population response patterns, a shift from synchronous to asynchronous states and a decline in neural variability. To elucidate the mechanisms underlying these response properties and explore how they are mechanistically related, we develop a neural circuit model that incorporates two essential features widely observed in the cerebral cortex. The first feature is a balance between excitatory and inhibitory inputs to individual neurons; the second feature is distance-dependent connectivity. We show that applying a weak external stimulus to the model evokes a wave pattern propagating along lateral connections, but a strong external stimulus triggers a localized pattern; these stimulus strength-dependent population response patterns are quantitatively comparable with those measured in experimental studies. We identify network mechanisms underlying this population response, and demonstrate that the dynamics of population-level response patterns can explain a range of prominent features in neural responses, including changes to the dynamics of neurons' membrane potentials and synaptic inputs that characterize the shift of cortical states, and the stimulusevoked decline in neuron response variability. Our study provides a unified population activity pattern-based view of diverse cortical response properties, thus shedding new insights into cortical processing.},
author = {Keane, Adam and Henderson, James A. and Gong, Pulin},
doi = {10.1098/rsif.2017.0960},
file = {:home/vbaker/neuron/lit/Dynamic patterns underlying response properties of cortical circuits.pdf:pdf},
issn = {17425662},
journal = {Journal of the Royal Society Interface},
keywords = {Asynchronous state,Balanced excitation and inhibition,Cortical circuits,Neural response properties,Neural variability},
number = {140},
pmid = {29593086},
title = {{Dynamical patterns underlying response properties of cortical circuits}},
volume = {15},
year = {2018}
}
@article{izhikevich2003,
abstract = {A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin-Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop PC.},
author = {Izhikevich, Eugene M.},
doi = {10.1109/TNN.2003.820440},
file = {:home/vbaker/neuron/lit/Izhikevich model of spiking neurons.pdf:pdf},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Bursting,Cortex,Hodgkin-Huxley,PCNN,Quadratic integrate-and-fire,Spiking,Thalamus},
number = {6},
pages = {1569--1572},
pmid = {18244602},
title = {{Simple model of spiking neurons}},
volume = {14},
year = {2003}
}
@article{VanRossum2000,
abstract = {We explore a synaptic plasticity model that incorporates recent findings that potentiation and depression can be induced by precisely timed pairs of synaptic events and postsynaptic spikes. In addition we include the observation that strong synapses undergo relatively less potentiation than weak synapses, whereas depression is independent of synaptic strength. After random stimulation, the synaptic weights reach an equilibrium distribution which is stable, unimodal, and has positive skew. This weight distribution compares favorably to the distributions of quantal amplitudes and of receptor number observed experimentally in central neurons and contrasts to the distribution found in plasticity models without size-dependent potentiation. Also in contrast to those models, which show strong competition between the synapses, stable plasticity is achieved with little competition. Instead, competition can be introduced by including a separate mechanism that scales synaptic strengths multiplicatively as a function of postsynaptic activity. In this model, synaptic weights change in proportion to how correlated they are with other inputs onto the same postsynaptic neuron. These results indicate that stable correlation-based plasticity can be achieved without introducing competition, suggesting that plasticity and competition need not coexist in all circuits or at all developmental stages.},
author = {{Van Rossum}, M. C.W. and Bi, G. Q. and Turrigiano, G. G.},
doi = {10.1523/jneurosci.20-23-08812.2000},
file = {:home/vbaker/neuron/lit/ML/Stable Hebbian learning from STDP.pdf:pdf},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {Activity-dependent scaling,Hebbian plasticity,Stochastic approaches,Synaptic competition,Synaptic weights,Temporal learning},
number = {23},
pages = {8812--8821},
pmid = {11102489},
title = {{Stable Hebbian learning from spike timing-dependent plasticity}},
volume = {20},
year = {2000}
}
@article{cruz2000,
abstract = {The cortex of the brain is organized into clear horizontal layers, laminae, which subserve much of the connectional anatomy of the brain. We hypothesize that there is also a vertical anatomical organization that might subserve local interactions of neuronal functional units, in accord with longstanding electrophysiological observations. We develop and apply a general quantitative method, inspired by analogous methods in condensed matter physics, to examine the anatomical organization of the cortex in human brain. We find, in addition to obvious laminae, anatomical evidence for tightly packed microcolumnar ensembles containing approximately 11 neurons, with a periodicity of about 80 $\mu$m. We examine the structural integrity of this new architectural feature in two common dementing illnesses, Alzheimer disease and dementia with Lewy bodies. In Alzheimer disease, there is a dramatic, nearly complete loss of microcolumnar ensemble organization. The relative degree of loss of microcolumnar ensembles is directly proportional to the number of neurofibrillary tangles, but not related to the amount of amyloid-$\beta$ deposition. In dementia with Lewy bodies, a similar disruption of microcolumnar ensemble architecture occurs despite minimal neuronal loss. These observations show that quantitative analysis of complex cortical architecture can be applied to analyze the anatomical basis of brain disorders.},
author = {Buldyrev, S. V. and Cruz, L. and Gomez-Isla, T. and Gomez-Tortosa, E. and Havlin, S. and Le, R. and Stanley, H. E. and Urbanc, B. and Hyman, B. T.},
doi = {10.1073/pnas.060009897},
file = {:home/vbaker/neuron/lit/bio/Description of microcolumnar ensembles in association cortex and their disruption in Alzheimer and Lewy body dementias.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {10},
pages = {5039--5043},
pmid = {10805766},
title = {{Description of microcolumnar ensembles in association cortex and their disruption in Alzheimer and Lewy body dementias}},
volume = {97},
year = {2000}
}
@article{Golomb1996,
abstract = {1. We study the propagation and dynamics of spindle waves in thalamic slices by developing and analyzing a model of reciprocally coupled populations of excitatory thalamocortical (TC) neurons and inhibitory thalamic reticular (RE) neurons. 2. Each TC neuron has three intrinsic ionic currents: a low-threshold T type Ca+2 current (I(Ca-T)), a hyperpolarization-activated cation ('sag') current (I(h)), and a leak current. Each RE cell also has three currents: I(Ca-T), a leak current, and a calcium-activated potassium current (I(AHP)). Isolated TC cells are at rest, can burst when released or depolarized from a hyperpolarized level, and burst rhythmically under moderate constant hyperpolarizing current. Isolated RE cells are at a hyperpolarized resting membrane potential and can burst when depolarized. 3. TC cells excite RE cells with fast $\alpha$-amino-3-hydroxy-5- methyl-4-isoxazolepropionic acid (AMPA) synapses, and RE cells inhibit TC cells with fast $\gamma$-aminobutyric acid-A (GABA(A)) and slow GABA(B) synapses and inhibit each other with GABA(A) synapses only. GABA(B) postsynaptic conductances operate far from saturation, and the slow inhibitory postsynaptic potentials (IPSPs) increase with the width of the presynaptic burst. The model network is a one-dimensional cellular array with localized coupling. The synaptic coupling strength decays with the distance between the pre- and postsynaptic cells, either exponentially or as a step function. 4. The 'intact' network can oscillate with partial synchrony and a population frequency of $\sim$10 Hz. RE cells emit bursts almost at every oscillation cycle, whereas TC cells do so almost at every other cycle. Block of GABA(B) receptors hardly changes the network behavior. Block of GABA(A) receptors leads the network to a slowed oscillatory state, where the population frequency is $\sim$4 Hz and both RE and TC cells fire unusually long bursts at every cycle and in full synchrony. These results are consistent with the experimental observations of von Krosigk, Bal, and McCormick. We obtain such consistency only when the above assumptions regarding the synaptic dynamics, particularly nonsaturating GABA(B) synapses, are fulfilled. 5. The slice model has a stable rest state with no neural activity. By initially depolarizing a few neurons at one end of the slice while all the other cells are at rest, a recruitment process may be initiated, and a wavefront of oscillatory activity propagates across the slice. Ahead of the wavefront, neurons are quiescent; neurons behind it oscillate. We find that the wave progresses forward in a lurching manner. TC cells that have just become inhibited must be hyperpolarized for a long enough time before they can fire rebound bursts and recruit RE cells. This step limits the wavefront velocity and may involve a substantial part of the cycle when no cells at the front are depolarized. 6. The wavefront velocity increases linearly with the characteristic spatial length of the connectivity (the footprint length). It increases only gradually with the synaptic strength, logarithmically in the case of an exponential connection function and only slightly for a step connection function. It also decreases gradually with a potassium leak conductance that hyperpolarizes RE cells. 7. To reproduce the experimentally measured wavefront velocity of $\sim$1 mm/s, together with other in vitro observations, both the RE-to-TC and the TC-to-RE projections in the model should be spatially localized. The sum of the RE-to-TC and the TC-to-RE synaptic footprint lengths should be on the order of 100 $\mu$m. 8. Neurons at different positions along the slice model oscillate with different phases. In the case of GABA(A) blockade, the phase shifts increase linearly with the distance between neurons and decay only slowly with time. Depending on parameter values, the phase shift can be positive or negative, because in a given bursting cycle a neuron lites before or after those on its right side, respectively. With GABA(A) intact, the phase shift's dependence on interneuronal distance can fluctuate and be more complex. 9. In addition to a propagating wavefront, the network can display various other types of spatiotemporal behaviors as parameter values and initial conditions are varied. Even a few endogenously oscillating cells, as expected in a heterogeneous population, can lead to several initiation points for waves propagating in both directions. The isolated RE network can oscillate with partial synchrony if the RE cells are less hyperpolarized, similar to in vivo results on the isolated RE nucleus by Steriade and colleagues.},
author = {Golomb, David and Wang, Xiao Jing and Rinzel, John},
doi = {10.1152/jn.1996.75.2.750},
file = {:home/vbaker/neuron/lit/Propagation of Spindle Waves in a Thalamic Slice Model .pdf:pdf},
issn = {00223077},
journal = {Journal of Neurophysiology},
number = {2},
pages = {750--769},
pmid = {8714650},
title = {{Propagation of spindle waves in a thalamic slice model}},
volume = {75},
year = {1996}
}
@article{Cruz2009,
abstract = {The age-related decline in cognitive function that is observed in normal aging monkeys and humans occurs without significant loss of cortical neurons. This suggests that cognitive impairment results from subtle, sub-lethal changes in the cortex. Recently, changes in the structural coherence in mini- or microcolumns without loss of neurons have been linked to loss of function. Here we use a density map method to quantify microcolumnar structure in both banks of the sulcus principalis (prefrontal cortical area 46) of 16 (ventral) and 19 (dorsal) behaviorally tested female rhesus monkeys from 6 to 33 years of age. While total neuronal density does not change with age in either of these banks, there is a significant age-related reduction in the strength of microcolumns in both regions on the order of 40%. This likely reflects a subtle but definite loss of organization in the structure of the cortical microcolumn. The reduction in strength in ventral area 46 correlates with cognitive impairments in learning and memory while the reduction in dorsal area 46 does not. This result is congruent with published data attributing cognitive functions to ventral area 46 that are similar to our particular cognitive battery which does not optimally tap cognitive functions attributed to dorsal area 46. While the exact mechanisms underlying this loss of microcolumnar organization remain to be determined, it is plausible that they reflect age-related alterations in dendritic and/or axonal organization which alter connectivity and may contribute to age-related declines in cognitive performance. {\textcopyright} 2009 IBRO.},
author = {Cruz, L. and Roe, D. L. and Urbanc, B. and Inglis, A. and Stanley, H. E. and Rosene, D. L.},
doi = {10.1016/j.neuroscience.2008.11.033},
file = {:home/vbaker/neuron/lit/bio/Age-related reduction in microcolumnar structure correlates with cognitive decline in rhesus monkey.pdf:pdf},
isbn = {1215895593},
issn = {03064522},
journal = {Neuroscience},
keywords = {aging,cognition,microcolumns,minicolumns,neuronal organization,primate brain},
number = {4},
pages = {1509--1520},
pmid = {19105976},
publisher = {IBRO},
title = {{Age-related reduction in microcolumnar structure correlates with cognitive decline in ventral but not dorsal area 46 of the rhesus monkey}},
url = {http://dx.doi.org/10.1016/j.neuroscience.2008.11.033},
volume = {158},
year = {2009}
}
@article{Sakata2009,
abstract = {Spontaneous activity plays an important role in the function of neural circuits. Although many similarities between spontaneous and sensory-evoked neocortical activity have been reported, little is known about consistent differences between them. Here, using simultaneously recorded cortical populations and morphologically identified pyramidal cells, we compare the laminar structure of spontaneous and sensory-evoked population activity in rat auditory cortex. Spontaneous and evoked patterns both exhibited sparse, spatially localized activity in layer 2/3 pyramidal cells, with densely distributed activity in larger layer 5 pyramidal cells and putative interneurons. However, the propagation of spontaneous and evoked activity differed, with spontaneous activity spreading upward from deep layers and slowly across columns, but sensory responses initiating in presumptive thalamorecipient layers, spreading rapidly across columns. The similarity of sparseness patterns for both neural events and distinct spread of activity may reflect similarity of local processing and differences in the flow of information through cortical circuits, respectively. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Sakata, Shuzo and Harris, Kenneth D.},
doi = {10.1016/j.neuron.2009.09.020},
file = {:home/vbaker/neuron/lit/Laminar Structure of Spontaneous and Sensory-Evoked Population Activity in Auditory Cortex.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
number = {3},
pages = {404--418},
pmid = {19914188},
publisher = {Elsevier Ltd},
title = {{Laminar Structure of Spontaneous and Sensory-Evoked Population Activity in Auditory Cortex}},
url = {http://dx.doi.org/10.1016/j.neuron.2009.09.020},
volume = {64},
year = {2009}
}
@article{Xu2007,
abstract = {Neuronal interactions between primary and secondary visual cortical areas are important for visual processing, but the spatiotemporal patterns of the interaction are not well understood. We used voltage-sensitive dye imaging to visualize neuronal activity in rat visual cortex and found visually evoked waves propagating from V1 to other visual areas. A primary wave originated in the monocular area of V1 and was "compressed" when propagating to V2. A reflected wave initiated after compression and propagated backward into V1. The compression occurred at the V1/V2 border, and local GABAA inhibition is important for the compression. The compression/reflection pattern provides a two-phase modulation: V1 is first depolarized by the primary wave, and then V1 and V2 are simultaneously depolarized by the reflected and primary waves, respectively. The compression/reflection pattern only occurred for evoked waves and not for spontaneous waves, suggesting that it is organized by an internal mechanism associated with visual processing. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Xu, Weifeng and Huang, Xiaoying and Takagaki, Kentaroh and young Wu, Jian},
doi = {10.1016/j.neuron.2007.06.016},
file = {:home/vbaker/neuron/lit/Compression and Reflection of Visually Evoked Cortical Waves.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {SIGNALING,SYSNEURO},
number = {1},
pages = {119--129},
pmid = {17610821},
title = {{Compression and Reflection of Visually Evoked Cortical Waves}},
volume = {55},
year = {2007}
}
@article{sanes1993,
abstract = {We investigated the occurrence and distribution of oscillatory activity in local field potentials (LFPs) recorded from the frontal motor cortex of behaving monkeys performing skilled voluntary movements. LFPs were recorded simultaneously from up to 12 sites distributed throughout motor cortex while monkeys performed a visually guided, instructed delay task using the wrist or digits. Oscillatory activity between 15 and 50 Hz was evident in the LFP recorded from both primary motor cortex and premotor areas. Oscillations occurred preferentially before the visual cue to initiate movement but were infrequent during movement. Oscillations typically stopped before movement initiation during the wrist task, although they often continued into the initial phases of movement during the digit task. The relationship of oscillations to task performance was consistent across trials over periods of many months, although the amplitude and duration of oscillations varied across trials and days. Interactions between pairs of LFP recordings, evaluated with cross-correlation analysis, revealed synchronous oscillations over long distances (>7 mm) and across primary motor cortex and premotor recording sites. These studies demonstrate that oscillations recorded in the LFP in motor cortex during trained motor tasks are not related to the details of movement execution but may be related to aspects of movement preparation.},
author = {Sanes, J. N. and Donoghue, J. P.},
doi = {10.1073/pnas.90.10.4470},
file = {:home/vbaker/neuron/lit/bio/Oscillations in local field potentials of the primate motor cortex.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {forearm,instructed voluntary movements,local neural circuits,monkeys,neural oscillations},
number = {10},
pages = {4470--4474},
pmid = {8506287},
title = {{Oscillations in local field potentials of the primate motor cortex during voluntary movement}},
volume = {90},
year = {1993}
}
@article{Coarer2018,
abstract = {We present in our work numerical results on the performance of a 4 × 4 swirl-topology photonic reservoir integrated on a silicon chip. Nonlinear microring resonators are used as nodes. We analyze the performance of such a reservoir on a classical nonlinear Boolean task (the delayed XOR task) for: various designs of the reservoir in terms of lengths of the waveguides between consecutive nodes, and various injection parameters (injected power and optical detuning). From this analysis, we find that this kind of reservoir can perform-for a large variety of parameters-the delayed XOR task at 20 Gb/s with bit error rates lower than 10-3 and an averaged injection power lower than 2.5 mW.},
author = {Coarer, Florian Denis Le and Sciamanna, Marc and Katumba, Andrew and Freiberger, Matthias and Dambre, Joni and Bienstman, Peter and Rontani, Damien},
doi = {10.1109/JSTQE.2018.2836985},
file = {:home/vbaker/neuron/lit/photonic/All Optical Reservoir Computing on a Photonic Chip using Silicon Based Ring Resonators.pdf:pdf},
issn = {21910359},
journal = {IEEE Journal of Selected Topics in Quantum Electronics},
keywords = {Reservoir computing,ring resonators,silicon photonics},
number = {6},
title = {{All-Optical Reservoir Computing on a Photonic Chip Using Silicon-Based Ring Resonators}},
volume = {24},
year = {2018}
}
@article{Qi2015,
abstract = {The formation of dynamic patterns such as localized propagating waves is a fascinating self-organizing phenomenon that happens in a wide range of spatially extended systems including neural systems, in which they might play important functional roles. Here we derive a type of two-dimensional neural-field model with refractoriness to study the formation mechanism of localized waves. After comparing this model with existing neural-field models, we show that it is able to generate a variety of localized patterns, including stationary bumps, localized waves rotating along a circular path, and localized waves with longer-range propagation. We construct explicit bump solutions for the two-dimensional neural field and conduct a linear stability analysis on how a stationary bump transitions to a propagating wave under different spatial eigenmode perturbations. The neural-field model is then partially solved in a comoving frame to obtain localized wave solutions, whose spatial profiles are in good agreement with those obtained from simulations. We demonstrate that when there are multiple such propagating waves, they exhibit rich propagation dynamics, including propagation along periodically oscillating and irregular trajectories; these propagation dynamics are quantitatively characterized. In addition, we show that these waves can have repulsive or merging collisions, depending on their collision angles and the refractoriness parameter. Due to its analytical tractability, the two-dimensional neural-field model provides a modeling framework for studying localized propagating waves and their interactions.},
author = {Qi, Yang and Gong, Pulin},
doi = {10.1103/PhysRevE.92.022702},
file = {:home/vbaker/neuron/lit/Dynamic patterns in a Two Dimensional Neural Field with Refractoriness.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {2},
pages = {1--13},
pmid = {26382427},
title = {{Dynamic patterns in a two-dimensional neural field with refractoriness}},
volume = {92},
year = {2015}
}
@article{Chervin1988,
abstract = {The horizontal propagation of epileptiform discharges has been studied in slices of neocortex treated with high concentrations of bicucullined methiodide, an antagonist of the inhibitory transmitter $\gamma$-aminobutyric acid (GABA). The cortical areas examined were: primary somatosensory (SmI) and motor (MI), and primary (area 17) and secondary (area 18) visual areas of rats, and area 17 of cats. In all of these areas an electrical stimulus evoked single, all-or-none paroxysmal field potentials (PFPs) that propagated across the entire width of the slice without decrement. The velocity of PFP propagation was $\sim$ 0.06-0.09 m/s when averaged over cortical distances of several millimeters. PFP propagation occurred equally well in both directions across a slice. Measurement of PFP propagation at higher spatial resolution (100-80 $\mu$m intervals) revealed that velocity was not homogeneous within rat SmI, rat area 18 and cat area 17, but instead varied manyfold as horizontal position changed. In these areas of cortex, propagation patterns were spatially periodic; power spectra reveal that the dominant spatial frequencies were centered about 1 mm-1, with negligible contributions above 2 mm-1. Occasionally PFP propagation was discontinuous, skipping over a small region of cortex and arriving distally before propagating into the more proximal region. In those cortices with periodic propagation patterns, PFP velocity was also strongly direction-dependent. Propagation patterns measured in opposite directions across the same strip of cortex displayed similar periodicities, but in many slices they were negatively correlated, i.e., the propagation pattern in one direction was antiphasic compared to that in the other direction. In contrast, propagation velocity across the center of area 17 of the rat was relatively constant and not directional. Near the boundaries of areas 17 of 18, however, PFP velocity changed abruptly and became periodic within area 18. Similarly, velocity within rat MI was more constant and less directional than in the adjacent SmI. The patterns of PFP propagation velocity are often spatially periodic, directionally asymmetric, and depend upon cortical area. We suggest that the periodic patterns reflect systematic variations in the length or density of horizontal excitatory connections. Alternatively, or concurrently, periodicities could arise from the patchy distributions of intrinsic connections that have been observed anatomically in many areas of neocortex.},
author = {Chervin, R. D. and Pierce, P. A. and Connors, B. W.},
doi = {10.1152/jn.1988.60.5.1695},
file = {:home/vbaker/neuron/lit/bio/Periodicity and directionality in the propagation of epileptiform discharges across neocortex.pdf:pdf},
issn = {00223077},
journal = {Journal of Neurophysiology},
number = {5},
pages = {1695--1713},
pmid = {3143812},
title = {{Periodicity and directionality in the propagation of epileptiform discharges across neocortex}},
volume = {60},
year = {1988}
}
@article{Kreuz2013,
abstract = {Recently, the SPIKE-distance has been proposed as a parameter-free and timescale-independent measure of spike train synchrony. This measure is time resolved since it relies on instantaneous estimates of spike train dissimilarity. However, its original definition led to spuriously high instantaneous values for eventlike firing patterns. Here we present a substantial improvement of this measure that eliminates this shortcoming. The reliability gained allows us to track changes in instantaneous clustering, i.e., time-localized patterns of (dis)similarity among multiple spike trains. Additional new features include selective and triggered temporal averaging as well as the instantaneous comparison of spike train groups. In a second step, a causal SPIKEdistance is defined such that the instantaneous values of dissimilarity rely on past information only so that time-resolved spike train synchrony can be estimated in real time. We demonstrate that these methods are capable of extracting valuable information from field data by monitoring the synchrony between neuronal spike trains during an epileptic seizure. Finally, the applicability of both the regular and the real-time SPIKE-distance to continuous data is illustrated on model electroencephalographic (EEG) recordings. {\textcopyright} 2013 the American Physiological Society.},
archivePrefix = {arXiv},
arxivId = {1209.6604},
author = {Kreuz, Thomas and Chicharro, Daniel and Houghton, Conor and Andrzejak, Ralph G. and Mormann, Florian},
doi = {10.1152/jn.00873.2012},
eprint = {1209.6604},
file = {:home/vbaker/neuron/lit/Monitoring spike train synchrony.pdf:pdf},
issn = {00223077},
journal = {Journal of Neurophysiology},
keywords = {Clustering,Data analysis,SPIKEdistance,Spike trains,Synchronization},
number = {5},
pages = {1457--1472},
pmid = {23221419},
title = {{Monitoring spike train synchrony}},
volume = {109},
year = {2013}
}
@article{Holzmann2010,
abstract = {Echo state networks (ESNs) are a novel approach to recurrent neural network training with the advantage of a very simple and linear learning algorithm. It has been demonstrated that ESNs outperform other methods on a number of benchmark tasks. Although the approach is appealing, there are still some inherent limitations in the original formulation. Here we suggest two enhancements of this network model. First, the previously proposed idea of filters in neurons is extended to arbitrary infinite impulse response (IIR) filter neurons. This enables such networks to learn multiple attractors and signals at different timescales, which is especially important for modeling real-world time series. Second, a delay&sum readout is introduced, which adds trainable delays in the synaptic connections of output neurons and therefore vastly improves the memory capacity of echo state networks. It is shown in commonly used benchmark tasks and real-world examples, that this new structure is able to significantly outperform standard ESNs and other state-of-the-art models for nonlinear dynamical system modeling. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Holzmann, Georg and Hauser, Helmut},
doi = {10.1016/j.neunet.2009.07.004},
file = {:home/vbaker/neuron/lit/ML/Echo state networks with filter neurons and a delay and sum readout.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Delay learning,Echo state networks,Nonlinear dynamical system modeling,Reservoir computing,Time series prediction},
number = {2},
pages = {244--256},
pmid = {19625164},
publisher = {Elsevier Ltd},
title = {{Echo state networks with filter neurons and a delay&sum readout}},
url = {http://dx.doi.org/10.1016/j.neunet.2009.07.004},
volume = {23},
year = {2010}
}
@article{Kopell1986,
abstract = {Weakly coupled chains of oscillators with nearest‐neighbor interactions are analyzed for phaselocked solutions. It is shown that the symmetry properties of the coupling affect the qualitative form of the phaselocked solutions and the scaling behavior of the system as the number of oscillators grows without bound. It is also shown that qualitative behavior of these solutions depends on whether the coupling is “diffusive” or “I synaptic”. terms defined in the paper. The methods include the demonstration that the equations for phaselocked solutions can be approximated by a singularly perturbed two‐point (continuum) boundary value problem that is easier to analyze; the issue of convergence of the phaselocked solutions to solutions of the continuum equation is closely related to questions involving numerical entropy in computation schemes for a conservation law. An application to the neurophysiology of motor behavior is discussed briefly. Copyright {\textcopyright} 1986 Wiley Periodicals, Inc., A Wiley Company},
author = {Kopell, N. and Ermentrout, G. B.},
doi = {10.1002/cpa.3160390504},
issn = {00103640},
journal = {Communications on Pure and Applied Mathematics},
month = {sep},
number = {5},
pages = {623--660},
publisher = {John Wiley & Sons, Ltd},
title = {{Symmetry and phaselocking in chains of weakly coupled oscillators}},
url = {http://doi.wiley.com/10.1002/cpa.3160390504},
volume = {39},
year = {1986}
}
@article{Golomb1997,
abstract = {We studied the propagation of paroxysmal discharges in disinhibited neocortical slices by developing and analyzing a model of excitatory regular- spiking neocortical cells with spatially decaying synaptic efficacies and by field potential recording in rat slices. Evoked discharges may propagate both in the model and in the experiment. The model discharge propagates as a traveling pulse with constant velocity and shape. The discharge shape is determined by an interplay between the synaptic driving force and the neuron's intrinsic currents, in particular the slow potassium current. In the model, N-methyl-D-aspartate (NMDA) conductance contributes much less to the discharge velocity than amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) conductance. Blocking NMDA receptors experimentally with 2-amino-5- phosphonovaleric acid (APV) has no significant effect on the discharge velocity. In both model and experiments, propagation occurs for AMPA synaptic coupling g(AMPA) above a certain threshold, at which the velocity is finite (non-zero). The discharge velocity grows linearly with the g(AMPA) for g(AMPA) much above the threshold. In the experiments, blocking AMPA receptors gradually by increasing concentrations of 6-cyano-7-nitroquinoxaline-2,3- dione (CNQX) in the perfusing solution results in a gradual reduction of the discharge velocity until propagation stops altogether, thus confirming the model prediction. When discharges are terminated in the model by the slow potassium current, a network with the same parameter set may display discharges with several forms, which have different velocities and numbers of spikes; initial conditions select the exhibited pattern. When the discharge is also terminated by strong synaptic depression, there is only one discharge form for a particular parameter set; the velocity grows continuously with increased synaptic conductances. No indication for more than one discharge velocity was observed experimentally. If the AMPA decay rate increases while the maximal excitatory postsynaptic conductance (EPSC) a cell receives is kept fixed, the velocity increases by $\sim$20% until it reaches a saturated value. Therefore the discharge velocity is determined mainly by the cells' integration time of input EPSCs. We conclude, on the basis of both the experiments and the model, that the total amount of excitatory conductance a typical cell receives in a control slice exhibiting paroxysmal discharges is only $\sim$5 times larger than the excitatory conductance needed for raising the potential of a resting cell above its action potential threshold.},
author = {Golomb, David and Amitai, Yael},
doi = {10.1152/jn.1997.78.3.1199},
file = {:home/vbaker/neuron/lit/bio/Propagating Neuronal Discharges in Neocortical Slices\: Computational and Experimental Study.pdf:pdf},
issn = {00223077},
journal = {Journal of Neurophysiology},
number = {3},
pages = {1199--1211},
pmid = {9310412},
title = {{Propagating neuronal discharges in neocortical slices: Computational and experimental study}},
volume = {78},
year = {1997}
}
@article{Zhang2015,
abstract = {The aims in this thesis were (1) to identify the causes of relatively poor reproductive performance of Bali cattle in Timor-Leste and (2) propose potential strategies to enhance reproductive performance within the economic, resource and environmental constraints in the country. In Study 1, a survey was undertaken to record herd age and gender profiles, the general condition of cattle, and reproductive characteristics across 800 cattle in seven districts. The average body condition score (BCS; scale 1-5) for all cattle surveyed was 3.4 (range 2.5-5.0). Reproductive indices were recorded for 477 females of reproductive age (≥ 20 months). Lactation status was influenced by age and pregnancy was influenced by BCS and lactation. No lactating cows were recorded pregnant. Pregnancy, lactation, and calving rates were 13%, 34% and 35%, respectively. Average age at first calving was 29 months (range 20-40 months) and the average inter-calving interval was 16 months (range 11-40 months). The majority (72%) of calves were born during the dry season and the mortality rate was around 46%. In Study 2, cattle were surveyed in four districts (3 districts were included in Study 1) and an attempt was made to ascertain the prevalence of bovine brucellosis in a sample of 300 females of reproductive age. Brucellosis was detected in 23% of cattle sampled. The average BCS was 3.8 (range 3.0-4.5) and the pregnancy, lactation, and calving rates were 56%, 26% and 54%, respectively. Age at first calving and inter-calving interval were 37 months and 15 months, respectively. Similar to Study 1, 76% of calves were born during the dry season with calf mortality around 33%. There was an apparent difference in pregnancy rate between the two studies suggesting an important influence of yearly differences in the pattern and amount of rainfall on reproduction. The relatively high calf mortality recorded in both studies was likely related, at least in part, to the birth of calves at the start- to mid-dry season when feed is limited and lactating cows would have difficulty in meeting the nutritional requirements of calves. Bali calves are relatively small at birth which probably also contributes to the high mortality relative to other cattle breeds. A potential solution to the relatively high calf mortality is to control the time of mating so that calves are born towards the end of the dry season and early wet season. Only 40% of breeding age females (≥ 20 months) were either pregnant or lactating, indicating that a relatively high proportion of females were not contributing to reproduction. Lactating cows did not re-conceive suggesting that weaning strategies could be implemented to increase herd reproductive performance. Weaning would need to be accompanied by supplementary feeding of calves. The occurrence of brucellosis appears to be a further constraint to reproduction. The management of mating, and hence calving, relative to seasonal cycles of pasture availability, and the control of reproductive diseases, are strategies to improve the reproductive performance of Bali cattle in Timor-Leste.},
author = {Zhang, Yong and Li, Peng and Member, Senior and Jin, Yingyezhe and Choe, Yoonsuck and Member, Senior},
file = {:home/vbaker/neuron/lit/ML/A Digital Liquid State Machine with Biologically Inspired Learning and Its Applications to Speech Recognition.pdf:pdf},
keywords = {11,26,e transactions on neural,networks and learning systems,no,november 2015,vol},
number = {November},
pages = {1--15},
title = {{Inspired Learning and Its Application to Speech Recognition}},
volume = {26},
year = {2015}
}
@article{horton2005,
abstract = {This year, the field of neuroscience celebrates the 50th anniversary of Mountcastle's discovery of the cortical column. In this review, we summarize half a century of research and come to the disappointing realization that the column may have no function. Originally, it was described as a discrete structure, spanning the layers of the somatosensory cortex, which contains cells responsive to only a single modality, such as deep joint receptors or cutaneous receptors. Subsequently, examples of columns have been uncovered in numerous cortical areas, expanding the original concept to embrace a variety of different structures and principles. A 'column' now refers to cells in any vertical cluster that share the same tuning for any given receptive field attribute. In striate cortex, for example, cells with the same eye preference are grouped into ocular dominance columns. Unaccountably, ocular dominance columns are present in some species, but not others. In principle, it should be possible to determine their function by searching for species differences in visual performance that correlate with their presence or absence. Unfortunately, this approach has been to no avail; no visual faculty has emerged that appears to require ocular dominance columns. Moreover, recent evidence has shown that the expression of ocular dominance columns can be highly variable among members of the same species, or even in different portions of the visual cortex in the same individual. These observations deal a fatal blow to the idea that ocular dominance columns serve a purpose. More broadly, the term 'column' also denotes the periodic termination of anatomical projections within or between cortical areas. In many instances, periodic projections have a consistent relationship with some architectural feature, such as the cytochrome oxidase patches in V1 or the stripes in V2. These tissue compartments appear to divide cells with different receptive field properties into distinct processing streams. However, it is unclear what advantage, if any, is conveyed by this form of columnar segregation. Although the column is an attractive concept, it has failed as a unifying principle for understanding cortical function. Unravelling the organization of the cerebral cortex will require a painstaking description of the circuits, projections and response properties peculiar to cells in each of its various areas. {\textcopyright} 2005 The Royal Society.},
author = {Horton, Jonathan G. and Adams, Daniel L.},
doi = {10.1098/rstb.2005.1623},
file = {:home/vbaker/neuron/lit/Cortical Column a Structure Without Function.pdf:pdf},
issn = {09628436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Angioscotoma,Barrel,Macaque,Pinwheel,Retinal wave,Spandrel},
number = {1456},
pages = {837--862},
pmid = {15937015},
title = {{The cortical column: A structure without a function}},
volume = {360},
year = {2005}
}
@article{Fok2010,
abstract = {We developed a hybrid analog/digital computational primitive that elegantly implements the functionality of an integrateand-fire neuron using a Ge-doped non-linear optical fiber and off-the-shelf semiconductor devices. Spike processing devices for optical computational system have the potential to be scalable, computationally powerful, and have high operation bandwidth. They open up a range of optical processing applications for which electronic processing is too slow. In this paper, we demonstrate the feasibility of implementing simple photonic neuromorphic circuits, including the auditory localization algorithm of the barn owl, which is useful for LIDAR localization, and the crayfish tail-flip escape response.},
author = {Fok, Mable P. and Rosenbluth, David and Kravtsov, Konstantin and Prucnal, Paul R.},
doi = {10.1049/cp.2010.1181},
file = {:home/vbaker/neuron/lit/photonic/Photonic_Neurons_for_TeraHz_Pulse_Processing.pdf:pdf},
isbn = {9781849193146},
journal = {IET Conference Publications},
keywords = {Gedoped nonlinear fiber,Lightwave neuromorphic signal processing,Optical neural systems,Semiconductor optical amplifier},
number = {574 CP},
pages = {188--189},
title = {{Photonic neurons for terahertz pulse processing}},
volume = {2010},
year = {2010}
}
@article{Tangetal.2008,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Tang et al., 2005},
doi = {10.1177/1073858408317066.Propagating},
eprint = {NIHMS150003},
file = {:home/vbaker/neuron/lit/CorticalWaves.pdf:pdf},
isbn = {6176321972},
issn = {15378276},
journal = {Bone},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
number = {1},
pages = {1--7},
pmid = {1000000221},
title = {{基因的改变NIH Public Access}},
volume = {23},
year = {2008}
}
@article{hayut2011,
abstract = {Somatostatin-expressing, low threshold-spiking (LTS) cells and fast-spiking (FS) cells are two common subtypes of inhibitory neocortical interneuron. Excitatory synapses from regular-spiking (RS) pyramidal neurons to LTS cells strongly facilitate when activated repetitively, whereas RS-to-FS synapses depress. This suggests that LTS neurons may be especially relevant at high rate regimes and protect cortical circuits against over-excitation and seizures. However, the inhibitory synapses from LTS cells usually depress, which may reduce their effectiveness at high rates. We ask: by which mechanisms and at what firing rates do LTS neurons control the activity of cortical circuits responding to thalamic input, and how is control by LTS neurons different from that of FS neurons? We study rate models of circuits that include RS cells and LTS and FS inhibitory cells with short-term synaptic plasticity. LTS neurons shift the RS firing-rate vs. current curve to the right at high rates and reduce its slope at low rates; the LTS effect is delayed and prolonged. FS neurons always shift the curve to the right and affect RS firing transiently. In an RS-LTS-FS network, FS neurons reach a quiescent state if they receive weak input, LTS neurons are quiescent if RS neurons receive weak input, and both FS and RS populations are active if they both receive large inputs. In general, FS neurons tend to follow the spiking of RS neurons much more closely than LTS neurons. A novel type of facilitation-induced slow oscillations is observed above the LTS firing threshold with a frequency determined by the time scale of recovery from facilitation. To conclude, contrary to earlier proposals, LTS neurons affect the transient and steady state responses of cortical circuits over a range of firing rates, not only during the high rate regime; LTS neurons protect against over-activation about as well as FS neurons. {\textcopyright} 2011 Hayut et al.},
author = {Hayut, Itai and Fanselow, Erika E. and Connors, Barry W. and Golomb, David},
doi = {10.1371/journal.pcbi.1002248},
file = {:home/vbaker/neuron/lit/LTS and FTS Inhibitory Interneurons Short Term Synaptic Plasticity and Cortical Circuit Dynamics.PDF:PDF},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {10},
pmid = {22046121},
title = {{LTS and FS inhibitory interneurons, short-term synaptic plasticity, and cortical circuit dynamics}},
volume = {7},
year = {2011}
}
@article{Hughes2019,
abstract = {Analog machine learning hardware platforms promise to be faster and more energy-efficient than their digital counterparts. Wave physics, as found in acoustics and optics, is a natural candidate for building analog processors for time-varying signals. Here we identify a mapping between the dynamics of wave physics, and the computation in recurrent neural networks. This mapping indicates that physical wave systems can be trained to learn complex features in temporal data, using standard training techniques for neural networks. As a demonstration, we show that an inverse-designed inhomogeneous medium can perform vowel classification on raw audio signals as their waveforms scatter and propagate through it, achieving performance comparable to a standard digital implementation of a recurrent neural network. These findings pave the way for a new class of analog machine learning platforms, capable of fast and efficient processing of information in its native domain.},
author = {Hughes, Tyler W. and Williamson, Ian A.D. and Minkov, Momchil and Fan, Shanhui},
file = {:home/vbaker/neuron/lit/ML/Wave physics as an analog recurrent neural network.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {December},
pages = {1--7},
title = {{Wave physics as an analog recurrent neural network}},
year = {2019}
}
@article{Chella2009,
abstract = {The liquid state machine is a novel computation paradigm based on the tran- sient dynamics of recurrent neural circuitry. In this paper it is shown that this systems can be used to recognize complex stimuli composed by non-periodic signals and to classify them in a very short time. Even if the network is trained over a segment of the signal the classification task is completed in a time in- terval significantly shorter than the time-window used for the training. Stimuli composed by many complex signals are recognized and classified even if some signals are absent.},
author = {Chella, Antonio and Rizzo, Riccardo},
doi = {10.1007/1-4020-3432-6_16},
file = {:home/vbaker/neuron/lit/ML/Time varying signal classification using a liquid state machine.pdf:pdf},
journal = {Biological and Artificial Intelligence Environments},
pages = {133--139},
title = {{Time-Varying Signals Classification Using a Liquid State Machine}},
year = {2009}
}
@article{Markov2011,
abstract = {To what extent cortical pathways show significant weight differences and whether these differences are consistent across animals (thereby comprising robust connectivity profiles) is an important and unresolved neuroanatomical issue. Here we report a quantitative retrograde tracer analysis in the cynomolgus macaque monkey of the weight consistency of the afferents of cortical areas across brains via calculation of a weight index (fraction of labeled neurons, FLN). Injection in 8 cortical areas (3 occipital plus 5 in the other lobes) revealed a consistent pattern: small subcortical input (1.3% cumulative FLN), high local intrinsic connectivity (80% FLN), high-input form neighboring areas (15% cumulative FLN), and weak long-range corticocortical connectivity (3% cumulative FLN). Corticocortical FLN values of projections to areas V1, V2, and V4 showed heavy-tailed, lognormal distributions spanning 5 orders of magnitude that were consistent, demonstrating significant connectivity profiles. These results indicate that 1) connection weight heterogeneity plays an important role in determining cortical network specificity, 2) high investment in local projections highlights the importance of local processing, and 3) transmission of information across multiple hierarchy levels mainly involves pathways having low FLN values. {\textcopyright} The Author 2010. Published by Oxford University Press. All rights reserved.},
author = {Markov, N. T. and Misery, P. and Falchier, A. and Lamy, C. and Vezoli, J. and Quilodran, R. and Gariel, M. A. and Giroud, P. and Ercsey-Ravasz, M. and Pilaz, L. J. and Huissoud, C. and Barone, P. and Dehay, C. and Toroczkai, Z. and {Van Essen}, D. C. and Kennedy, H. and Knoblauch, K.},
doi = {10.1093/cercor/bhq201},
file = {:home/vbaker/neuron/lit/bio/Weight Consistency Specifies Regularities of Macaque Cortical Networks.pdf:pdf},
issn = {14602199},
journal = {Cerebral Cortex},
keywords = {amygdala,area 17,macaque,network,primate,thalamus},
number = {6},
pages = {1254--1272},
title = {{Weight consistency specifies regularities of macaque cortical networks}},
volume = {21},
year = {2011}
}
@article{Maass2011,
abstract = {The Liquid State Machine (LSM) has emerged as a computational model that is more adequate than the Turing machine for describing computations in biological networks of neurons. Characteristic features of this new model are (i) that it is a model for adaptive computational systems, (ii) that it provides a method for employing randomly connected circuits, or even “found” physical objects for meaningful computations, (iii) that it provides a theoretical context where heterogeneous, rather than stereo typical, local gates, or processors increase the computational power of a circuit, (iv) that it provides a method for multiplexing different computations (on a common input) within the same circuit. This chapter reviews the motivation for this model, its theoretical background, and current work on implementations of this model in innovative artificial computing devices.},
author = {Maass, Wolfgang},
doi = {10.1142/9781848162778_0008},
file = {:home/vbaker/neuron/lit/ML/Liquid State Machines Motivation Theory and Applications.pdf:pdf},
isbn = {9781848162778},
journal = {Computability in Context: Computation and Logic in the Real World},
pages = {275--296},
title = {{Liquid state machines: Motivation, theory, and applications}},
year = {2011}
}
@article{huang2004,
abstract = {Spiral waves are a basic feature of excitable systems. Although such waves have been observed in a variety of biological systems, they have not been observed in the mammalian cortex during neuronal activity. Here, we report stable rotating spiral waves in rat neocortical slices visualized by voltage-sensitive dye imaging. Tissue from the occipital cortex (visual) was sectioned parallel to cortical lamina to preserve horizontal connections in layers III-V (500-$\mu$m-thick, ∼4 × 6 mm2). In such tangential slices, excitation waves propagated in two dimensions during cholinergic oscillations. Spiral waves occurred spontaneously and alternated with plane, ring, and irregular waves. The rotation rate of the spirals was ×10 turns per second, and the rotation was linked to the oscillations in a one-cycle-one-rotation manner. A small (<128 $\mu$m) phase singularity occurred at the center of the spirals, about which were observed oscillations of widely distributed phases. The phase singularity drifted slowly across the tissue (∼1 mm/10 turns). We introduced a computational model of a cortical layer that predicted and replicated many of the features of our experimental findings. We speculate that rotating spiral waves may provide a spatial framework to organize cortical oscillations.},
author = {Huang, Xiaoying and Troy, William C. and Yang, Qian and Ma, Hongtao and Laing, Carlo R. and Schiff, Steven J. and Wu, Jian Young},
doi = {10.1523/JNEUROSCI.2705-04.2004},
file = {:home/vbaker/neuron/lit/bio/Spiral waves in disinhibited mammalian neocortex.pdf:pdf},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {Optical imaging,Oscillation,Partial differential equations,Spiral waves,Tangential slice,Voltage-sensitive dye},
number = {44},
pages = {9897--9902},
pmid = {15525774},
title = {{Spiral waves in disinhibited mammalian neocortex}},
volume = {24},
year = {2004}
}
@article{Peters1991,
abstract = {In sections of area 17 of monkey visual cortex treated with an antibody to MAP2 the disposition of the cell bodies and dendrites of the neurons is readily visible. In such preparations it is evident that the apical dendrites of the pyramidal cells of layer VI form fascicles that pass into layer IV, where most of them gradually taper and form their terminal tufts. In contrast, the apical dendrites of the smaller layer V pyramidal cells come together in a more regular fashion. They form clusters that pass through layer IV and into layer II/III where the apical dendrites of many of the pyramidal cells in that layer add to the clusters. In horizontal sections taken through the middle of layer IV, these clusters of apical dendrites are found to have an average center‐to‐center spacing of about 30 $\mu$m, and it is proposed that each cluster of apical dendrites represents the axis of a module of pyramidal cells that has a diameter of about 30 $\mu$m and contains about 142 neurons. The MAP2 antibody reaction also reveals that some pyramidal cells in layers IVA and IVB have their cell bodies arranged into cones. There are about 118 such cones beneath 1 mm2 of cortical surface and the apical dendrites of the pyramidal cells within them bundle together at the apex of each cone to pass into layer III. Surrounding the cones of neurons there are horizontally aligned, thin dendrites. The location of these dendrites coincides with the dark walls of the honeycomb pattern seen in layer IVA after cytochrome oxidase reactions, or after the parvocellular input from the lateral geniculate nucleus has been labeled. Thus the cones of pyramidal cells within upper layer IV fit into the pockets of the honeycomb pattern. Below the cones of pyramidal cells are the outer Meynert cells within layer IVB, and the cell bodies of these large neurons are disposed so that they preferentially lie beneath the neuropil between the cones of pyramids. It is suggested that pyramidal cell modules are a basic feature of the cerebral cortex, and that these are combined together by afferent inputs to the cortex to generate the systems of functional columns. Copyright {\textcopyright} 1991 Wiley‐Liss, Inc.},
author = {Peters, Alan and Sethares, Claire},
doi = {10.1002/cne.903060102},
file = {:home/vbaker/neuron/lit/bio/Organization of pyramidal neurons in area 17 of monkey visual cortex.pdf:pdf},
issn = {10969861},
journal = {Journal of Comparative Neurology},
keywords = {MAP2,Macaca mulatta,cytochrome oxidase,modules,pyramidal cells},
number = {1},
pages = {1--23},
pmid = {1710236},
title = {{Organization of pyramidal neurons in area 17 of monkey visual cortex}},
volume = {306},
year = {1991}
}
@article{Wyller2007,
abstract = {A two-population firing-rate model describing the dynamics of excitatory and inhibitory neural activity in one spatial dimension is investigated with respect to formation of patterns, in particular stationary periodic patterns and spatiotemporal oscillations. Conditions for existence of spatially homogeneous equilibrium states are first determined, and the stability properties of these equilibria are investigated. It is shown that the nonlocal synaptic interactions may promote a finite bandwidth instability in a way analogous to diffusion effects in the classical Turing instability for reaction-diffusion equations and modulational instability in the theory of nonlinear waves in nonlocal defocusing Kerr media. Our analysis relies on the wave-number dependent invariants of the 2×2-matrix representing the spatially Fourier-transformed linearized evolution equations. The generic picture which emerges is an instability consisting of a finite set of well-separated unstable bands in wave-number space (gain bands). The case with symmetrical, exponentially decaying connectivity functions is investigated in detail, allowing for a more comprehensive analysis of the gain-band structure, and, in particular, conditions for the excitation of a single gain band through a Turing-Hopf bifurcation with the relative inhibition time constant as control parameter. Two typical situations emerge depending on the thresholds and inclinations of the sigmoidal firing-rate functions: (i) A single gain-band is excited through a Turing-Hopf bifurcation, and the resulting state is a spatiotemporally oscillating pattern, or (ii) the instability develops into a stationary periodic pattern, i.e. a set of equidistant bumps. The dependence of instability-type on the inclinations of the firing-rate function and the time constant are comprehensively investigated, demonstrating, for example, that only stationary patterns can be generated for sufficiently small inhibitory time constants. The nonlinear development of the gain-band instabilities is further elucidated by direct numerical simulations. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Wyller, John and Blomquist, Patrick and Einevoll, Gaute T.},
doi = {10.1016/j.physd.2006.10.004},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {Neural network,Nonlocal,Pattern formation,Turing instability},
month = {jan},
number = {1},
pages = {75--93},
publisher = {Elsevier},
title = {{Turing instability and pattern formation in a two-population neuronal network model}},
volume = {225},
year = {2007}
}
@article{Levy2012,
abstract = {The role of local cortical activity in shaping neuronal responses is controversial. Among other questions, it is unknown how the diverse response patterns reported in vivo-lateral inhibition in some cases, approximately balanced excitation and inhibition (co-tuning) in others-compare to the local spread of synaptic connectivity. Excitatory and inhibitory activity might cancel each other out, or, whether one outweighs the other, receptive field properties might be substantially affected. As a step toward addressing this question, we used multiple intracellular recording in mouse primary auditory cortical slices to map synaptic connectivity among excitatory pyramidal cells and the two broad classes of inhibitory cells, fast-spiking (FS) and non-FS cells in the principal input layer. Connection probability was distance-dependent; the spread of connectivity, parameterized by Gaussian fits to the data, was comparable for all cell types, ranging from 85 to 114 $\mu$m. With brief stimulus trains, unitary synapses formed by FS interneurons were stronger than other classes of synapses; synapse strength did not correlate with distance between cells. The physiological data were qualitatively consistent with predictions derived from anatomical reconstruction. We also analyzed the truncation of neuronal processes due to slicing; overall connectivity was reduced but the spatial pattern was unaffected. The comparable spatial patterns of connectivity and relatively strong excitatoryinhibitory interconnectivity are consistent with a theoretical model where either lateral inhibition or co-tuning can predominate, depending on the structure of the input. {\textcopyright} 2012 the authors.},
author = {Levy, Robert B. and Reyes, Alex D.},
doi = {10.1523/jneurosci.5158-11.2012},
file = {:home/vbaker/neuron/lit/bio/Spatial Profile of Excitatory and Inhibitory Synaptic Connectivity in Mouse Primary Auditory Cortex.pdf:pdf},
issn = {02706474},
journal = {Journal of Neuroscience},
number = {16},
pages = {5609--5619},
pmid = {22514322},
title = {{Spatial profile of excitatory and inhibitory synaptic connectivity in mouse primary auditory cortex}},
volume = {32},
year = {2012}
}
@article{Mehring2003,
abstract = {Random network models have been a popular tool for investigating cortical network dynamics. On the scale of roughly a cubic millimeter of cortex, containing about 100,000 neurons, cortical anatomy suggests a more realistic architecture. In this locally connected random network, the connection probability decreases in a Gaussian fashion with the distance between neurons. Here we present three main results from a simulation study of the activity dynamics in such networks. First, for a broad range of parameters these dynamics exhibit a stationary state of asynchronous network activity with irregular single-neuron spiking. This state can be used as a realistic model of ongoing network activity. Parametric dependence of this state and the nature of the network dynamics in other regimes are described. Second, a synchronous excitatory stimulus to a fraction of the neurons results in a strong activity response that easily dominates the network dynamics. And third, due to that activity response an embedding of a divergent-convergent feed-forward subnetwork (as in synfire chains) does not naturally lead to a stable propagation of synchronous activity in the subnetwork; this is in contrast to our earlier findings in isolated subnetworks of that type. Possible mechanisms for stabilizing the interplay of volleys of synchronous spikes and network dynamics by specific learning rules or generalizations of the subnetworks are discussed.},
author = {Mehring, Carsten and Hehl, Ulrich and Kubo, Masayoshi and Diesmann, Markus and Aertsen, Ad},
doi = {10.1007/s00422-002-0384-4},
file = {:home/vbaker/neuron/lit/Activity dynamics and propagation of synchronous spiking in locally connected random networks.pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
number = {5},
pages = {395--408},
pmid = {12750902},
title = {{Activity dynamics and propagation of synchronous spiking in locally connected random networks}},
volume = {88},
year = {2003}
}
@article{Zhang2016,
abstract = {In contrast to other large-scale network models for propagation of electrical activity in neural tissue that have no analytical solutions for their dynamics, we show that for a specific class of integrate and fire neural networks the acceleration depends quadratically on the instantaneous speed of the activity propagation. We use this property to analytically compute the network spike dynamics and to highlight the emergence of a natural time scale for the evolution of the traveling waves. These results allow us to examine other applications of this model such as the effect that a nonconductive gap of tissue has on further activity propagation. Furthermore we show that activity propagation also depends on local conditions for other more general connectivity functions, by converting the evolution equations for network dynamics into a low-dimensional system of ordinary differential equations. This approach greatly enhances our intuition into the mechanisms of the traveling waves evolution and significantly reduces the simulation time for this class of models.},
author = {Zhang, Jie and Osan, Remus},
doi = {10.1103/PhysRevE.93.052228},
file = {:home/vbaker/neuron/lit/Analytically tractable studies of traveling waves of activity in integrate-and-fire neural networks.pdf:pdf},
issn = {24700053},
journal = {Physical Review E},
number = {5},
pages = {1--9},
pmid = {27300901},
title = {{Analytically tractable studies of traveling waves of activity in integrate-and-fire neural networks}},
volume = {93},
year = {2016}
}
@article{Kok2007,
abstract = {In this thesis several possibilities are investigated for improving the perfor- mance of Liquid State Machines. A Liquid State Machine is a relatively new system that is a Machine Learning system, which is capable of coping with temporal dependencies. Basic Recurrent Neural Networks often have prob- lems with this. One reason for this is that it takes a long time to train the Recurrent Neural Network. Liquid State Machines train much faster by us- ing a temporal reservoir to map temporal input into a static output pattern. These output patterns can be learned by a statistical learning method. In this thesis, two different subjects are addressed. The first subject is about reducing computation time on calculating the performance. Optimization algorithms for neural networks are often computationally heavy. This is be- cause the performance of the system, here the Liquid State Machine, needs to be evaluated. The computation time can be decreased by using other meth- ods to evaluate the performance. The other subject that is addressed here, is in the optimization of the temporal reservoir in the Liquid State Machine. Two different algorithms are used here, namely Reinforcement Learning and a Genetic Algorithm. The goal is to find out if the algorithms can improve the performance by improving the temporal reservoir and if so, if the per- formance is increased that much so that it is computationally beneficial to use. The experiments using a different performance measure showed that it will probably not help in improving the performance on classification of the Liquid State Machine. The other experiment using the two different algo- rithms showed that Reinforcement Learning can not find a better setting for the temporal reservoir to improve the performance given the settings of the experiments. But the Genetic Algorithm is able to improve the temporal reservoir and thus improve the performance, this was tested on two different datasets. The first dataset used was a movement classification task. The results showed an improvement, but comparing it to another system, namely Evolino, the Liquid State Machine is outperformed on both classification and computation time. The second dataset used is a music classification task. The results here where more in favor of the Liquid State Machine, although it is unclear if the parameter setting for Evolino is optimal.},
author = {Kok, Stefan},
file = {:home/vbaker/neuron/lit/ML/Liquid State Machine Optimization.pdf:pdf},
journal = {Thesis},
title = {{Liquid state machine optimization}},
url = {http://www.ai.rug.nl/$\sim$mwiering/thesis_kok.pdf},
year = {2007}
}
@article{Sato2012,
abstract = {Electrode recordings and imaging studies have revealed that localized visual stimuli elicit waves of activity that travel across primary visual cortex. Traveling waves are present also during spontaneous activity, but they can be greatly reduced by widespread and intensive visual stimulation. In this Review, we summarize the evidence in favor of these traveling waves. We suggest that their substrate may lie in long-range horizontal connections and that their functional role may involve the integration of information over large regions of space.},
author = {Sato, Tatsuo K. and Nauhaus, Ian and Carandini, Matteo},
doi = {10.1016/j.neuron.2012.06.029},
file = {:home/vbaker/neuron/lit/Traveling Waves in Visual Cortex.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {218--229},
pmid = {22841308},
title = {{Traveling Waves in Visual Cortex}},
volume = {75},
year = {2012}
}
@article{cruz2005,
abstract = {We present a statistical density map method derived from condensed matter physics to quantify microcolumns, the fundamental computational unit of the cerebral cortex. This method provides measures for microcolumnar strength, width, spacing, length, and periodicity. We applied this method to Nissl-stained 30 $\mu$m thick frozen sections from areas 46, TE, and TL of rhesus monkey brains, areas that differ visually in microcolumnarity and are associated with different cognitive functions. Our results indicate that microcolumns in these areas are similar in width, spacing, and periodicity, but are stronger (possess a higher neuronal density) in area TE, as compared to areas TL and 46. We modeled the effect of section orientation on microcolumnar spacing and demonstrated that this method provides an adequate estimate of spacing. We also modeled disruption of microcolumnarity by performing simulations that randomly displace neurons and demonstrated that displacements of only one neuronal diameter effectively eliminate microcolumnar organization. These results indicate that our density map method is sensitive enough to detect and quantify subtle differences in microcolumnar organization that may occur in the context of development, aging, and neuropathology, as well as between areas and species. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Cruz, Luis and Buldyrev, Sergey V. and Peng, Shouyong and Roe, Daniel L. and Urbanc, Brigita and Stanley, H. E. and Rosene, Douglas L.},
doi = {10.1016/j.jneumeth.2004.09.005},
file = {:home/vbaker/neuron/lit/bio/A statistically based density map method for identification of microcolumnarity in the monkey brain.pdf:pdf},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
keywords = {Cerebral cortex,Correlation,Microcolumns,Modeling,Neuronal organization,Primate brain},
number = {2},
pages = {321--332},
pmid = {15661314},
title = {{A statistically based density map method for identification and quantification of regional differences in microcolumnarity in the monkey brain}},
volume = {141},
year = {2005}
}
@article{Markram1997,
abstract = {1. Dual voltage recordings were made from pairs of adjacent, synaptically connected thick tufted layer 5 pyramidal neurones in brain slices of young rat (14-16 days) somatosensory cortex to examine the physiological properties of unitary EPSPs. Pre- and postsynaptic neurones were filled with biocytin and examined in the light and electron microscope to quantify the morphology of axonal and dendritic arbors and the number and location of synaptic contacts on the target neurone. 2. In 138 synaptic connections between pairs of pyramidal neurones 96 (70%) were unidirectional and 42 (30%) were bidirectional. The probability of finding a synaptic connection in dual recordings was 0.1. Unitary EPSPs evoked by a single presynaptic action potential (AP) had a mean peak amplitude ranging from 0.15 to 5.5 mV in different connections with a mean of 1.3 ± 1.1 mV, a latency of 1.7 ± 0.9 ms, a 20-80% rise time of 2.9 ± 2.3 ms and a decay time constant of 40 ± 18 ms at 32-34°C and -6O ± 2 mV membrane potential. 3. Peak amplitudes of unitary EPSPs fluctuated randomly from trial to trial. The coefficient of variation (c.v.) of the unitary EPSP amplitudes ranged from 0.13 to 2.8 in different synaptic connections (mean, 0.52; median, 0.41). The percentage of failures of single APs to evoke a unitary EPSP ranged from 0 to 73% (mean, 14%; median, 7%). Both c.v. and percentage of failures decreased with increasing mean EPSP amplitude. 4. Postsynaptic glutamate receptors which mediate unitary EPSPs at -6O mV were predominantly of the L-$\alpha$-amino-3-hydroxy-5-methyl-4-isoxazolepropionate (AMPA) receptor type. Receptors of the N-methyl-D-aspartate (NMDA) type contributed only a small fraction (< 20%) to the voltage-time integral of the unitary EPSP at -60 mV, but their contribution increased at more positive membrane potentials. 5. Branching patterns of dendrites and axon collaterals of forty-five synaptically connected neurones, when examined in the light microscope, indicated that the axonal and dendritic anatomy of both projecting and target neurones and of uni- and bidirectionally connected neurones was uniform. 6. The number of potential synaptic contacts formed by a presynaptic neurone on a target neurone varied between four and eight (mean, 5.5 ± 1.1 contacts; n = 19 connections). Synaptic contacts were preferentially located on basal dendrites (63%, 82 ± 35 $\mu$m from the soma, n = 67) and apical oblique dendrites (27%, 145 ± 59 $\mu$m, n = 29), and 35% of all contacts were located on tertiary basal dendritic branches. The mean geometric distances (from the soma) of the contacts of a connection varied between 80 and 585 $\mu$m (mean, 147 $\mu$m; median, 105 $\mu$m). The correlation between EPSP amplitude and the number of morphologically determined synaptic contacts or the mean geometric distances from the soma was only weak (correlation coefficients were 0.2 and 0.26, respectively). 7. Compartmental models constructed from camera lucida drawings of eight target neurones showed that synaptic contacts were located at mean electrotonic distances between 0.07 and 0.33 from the soma (mean, 0.13). Simulations of unitary EPSPs, assuming quantal conductance changes with fast rise time and short duration, indicated that amplitudes of quantal EPSPs at the soma were attenuated, on average, to < 10% of dendritic EPSPs and varied in amplitude up to 10-fold depending on the dendritic location of synaptic contacts. The inferred quantal peak conductance increase varied between 1.5 and 5.5 nS (mean, 3 nS). 8. The combined physiological and morphological measurements in conjunction with EPSP simulations indicated that the 20-fold range in efficacy of the synaptic connections between thick tufted pyramidal neurones, which have their synaptic contacts preferentially located on basal and apical oblique dendrites, was due to differences in transmitter release probability of the projecting neurones and, to a lesser extent, to differences in the number of release sites per bouton or quantal size. 9. The continuum of efficacies in their synaptic connections implies that layer 5 pyramidal neurones can be recruited to ensemble electrical activity via their axon collaterals if as few as five of the strongly and reliably connected neighbouring neurones are active synchronously, whereas coincident APs of as many as 100 of the weakly connected pyramidal neurones are necessary.},
author = {Markram, Henry and L{\"{u}}bke, Joachim and Frotscher, Michael and Roth, Arnd and Sakmann, Bert},
doi = {10.1113/jphysiol.1997.sp022031},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Markram et al. - 1997 - Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neo.pdf:pdf},
issn = {00223751},
journal = {Journal of Physiology},
month = {apr},
number = {2},
pages = {409--440},
pmid = {9147328},
publisher = {Blackwell Publishing Ltd},
title = {{Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex}},
url = {/pmc/articles/PMC1159394/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1159394/},
volume = {500},
year = {1997}
}
@article{Schrauwen2003,
abstract = {In this paper we introduce a new algorithm for encoding analog information into spike trains, given that the reconstruction will take place using a FIR filter. An older technique called HSA is reviewed and an optimal threshold value is found. A new technique called BSA is introduced. These methods are then compared experimentally.},
author = {Schrauwen, Benjamin and {Van Campenhout}, Jan},
doi = {10.1109/ijcnn.2003.1224019},
file = {:home/vbaker/neuron/lit/BSA A Fast and Accurate Spike Train Encoding Scheme.pdf:pdf},
isbn = {0780378989},
journal = {Proceedings of the International Joint Conference on Neural Networks},
pages = {2825--2830},
title = {{BSA, a Fast and Accurate Spike Train Encoding Scheme}},
volume = {4},
year = {2003}
}
@article{Otte2015,
abstract = {This paper presents an efficient and powerful approach for learning dynamics with Recurrent Neural Networks (RNNs). No specialized or fine-tuned RNNs are used but rather standard RNNs with one fully connected hidden layer. The training procedure is based on a variant of Differential Evolution (DE) with a modified mutation schemey that allows to reduce the population size in our setup down to five, but still yields very good results even within a few generations. For several common Multiple Superimposed Oscillator (MSO) instances new state-of-the-art results are presented, which are across the board multiple magnitudes better than the achieved results published so far. Furthermore, for new and even more difficult instances, i.e., MSO9-MSO12, our setup achieves lower error rates than reported previously for the best system on MSO5-MSO8.},
author = {Otte, Sebastian and Becker, Fabian and Butz, Martin V. and Liwicki, Marcus and Zell, Andreas},
file = {:home/vbaker/neuron/lit/ML/Learning recurrent dynamics using differential evolution.pdf:pdf},
isbn = {9782875870148},
journal = {23rd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2015 - Proceedings},
number = {April},
pages = {65--70},
title = {{Learning recurrent dynamics using Differential Evolution}},
year = {2015}
}
@article{wu2008,
abstract = {The development of voltage-sensitive dyes (VSD) and fast optical imaging techniques have brought us a new tool for examining spatiotemporal patterns of population neuronal activity in the neocortex. Propagating waves have been observed during almost every type of cortical processing examined by VSD imaging or electrode arrays. These waves provide subthreshold depolarization to individual neurons and increase their spiking probability. Therefore, the propagation of the waves sets up a spatiotemporal framework for increased excitability in neuronal populations, which can help to determine when and where the neurons are likely to fire. In this review, first discussed is propagating waves observed in various systems and possible mechanisms for generating and sustaining these waves. Then discussed are wave dynamics as an emergent behavior of the population activity that can, in turn, influence the activity of individual neurons. The functions of spontaneous and sensory-evoked waves remain to be explored. An important next step will be to examine the interaction between dynamics of propagating waves and functions in the cortex, and to verify if cortical processing can be modified when these waves are altered. Copyright {\textcopyright} 2008 Sage Publications.},
author = {Wu, Jian Young and Huang, Xiaoying and Zhang, Chuan},
doi = {10.1177/1073858408317066},
issn = {10738584},
journal = {Neuroscientist},
keywords = {Barrel cortex,Neuronal population activity,Propagating waves,Sensory processing,Visual cortex,Voltage-sensitive dye imaging},
number = {5},
pages = {487--502},
pmid = {18997124},
title = {{Propagating waves of activity in the neocortex: What they are, what they do}},
volume = {14},
year = {2008}
}
@article{Born2005,
abstract = {The small visual area known as MT or V5 has played a major role in our understanding of the primate cerebral cortex. This area has been historically important in the concept of cortical processing streams and the idea that different visual areas constitute highly specialized representations of visual information. MT has also proven to be a fertile culture dish-full of direction- and disparity-selective neurons-exploited by many labs to study the neural circuits underlying computations of motion and depth and to examine the relationship between neural activity and perception. Here we attempt a synthetic overview of the rich literature on MT with the goal of answering the question, What does MT do? Copyright {\textcopyright} 2005 by Annual Reviews. All rights reserved.},
author = {Born, Richard T. and Bradley, David C.},
doi = {10.1146/annurev.neuro.26.041002.131052},
file = {:home/vbaker/neuron/lit/Structure and Function of Visual Area MT.pdf:pdf},
issn = {0147006X},
journal = {Annual Review of Neuroscience},
keywords = {Aperture problem,Center-surround antagonism,Extrastriate,Magnocellular,Motion perception,Structure-from-motion},
pages = {157--189},
pmid = {16022593},
title = {{Structure and function of visual area MT}},
volume = {28},
year = {2005}
}
@article{Shoham1999,
abstract = {Conventional imaging techniques have provided high-resolution imaging either in the spatial domain or in the temporal domain. Optical imaging utilizing voltage-sensitive dyes has long had the unrealized potential to achieve high resolution in both domains simultaneously, providing subcolumnar spatial detail with millisecond precision. Here, we present a series of developments in voltage-sensitive dyes and instrumentation that make functional imaging of cortical dynamics practical, in both anesthetized and awake behaving preparations, greatly facilitating exploration of the cortex. We illustrate this advance by analyzing the millisecond-by-millisecond emergence of orientation maps in cat visual cortex.},
author = {Shoham, Doron and Glaser, Daniel E. and Arieli, Amos and Kenet, Tal and Wijnbergen, Chaipi and Toledo, Yuval and Hildesheim, Rina and Grinvald, Amiram},
doi = {10.1016/S0896-6273(00)81027-2},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shoham et al. - 1999 - Imaging cortical dynamics at high spatial and temporal resolution with novel blue voltage-sensitive dyes.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {A Grinvald,Animals,Brain Mapping,Cats,Cerebral Cortex / anatomy & histology*,Cerebral Cortex / physiology*,Coloring Agents*,Computer-Assisted / methods*,D E Glaser,D Shoham,Electrophysiology,Haplorhini,Heart Rate / physiology,Image Processing,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Orientation / physiology,Photic Stimulation,PubMed Abstract,Rats,Research Support,doi:10.1016/s0896-6273(00)81027-2,pmid:10624943},
number = {4},
pages = {791--802},
pmid = {10624943},
publisher = {Cell Press},
title = {{Imaging cortical dynamics at high spatial and temporal resolution with novel blue voltage-sensitive dyes}},
url = {https://pubmed.ncbi.nlm.nih.gov/10624943/},
volume = {24},
year = {1999}
}
@article{Nordlie2009,
abstract = {Progress in science depends on the effective exchange of ideas among scientists. New ideas can be assessed and criticized in a meaningful manner only if they are formulated precisely. This applies to simulation studies as well as to experiments and theories. But after more than 50 years of neuronal network simulations, we still lack a clear and common understanding of the role of computational models in neuroscience as well as established practices for describing network models in publications. This hinders the critical evaluation of network models as well as their re-use. We analyze here 14 research papers proposing neuronal network models of different complexity and find widely varying approaches to model descriptions, with regard to both the means of description and the ordering and placement of material. We further observe great variation in the graphical representation of networks and the notation used in equations. Based on our observations, we propose a good model description practice, composed of guidelines for the organization of publications, a checklist for model descriptions, templates for tables presenting model structure, and guidelines for diagrams of networks. The main purpose of this good practice is to trigger a debate about the communication of neuronal network models in a manner comprehensible to humans, as opposed to machine-readable model description languages. We believe that the good model description practice proposed here, together with a number of other recent initiatives on data-, model-, and softwaresharing, may lead to a deeper and more fruitful exchange of ideas among computational neuroscientists in years to come. We further hope that work on standardized ways of describing - and thinking about - complex neuronal networks will lead the scientific community to a clearer understanding of high-level concepts in network dynamics, and will thus lead to deeper insights into the function of the brain. {\textcopyright} 2009 Nordlie et al.},
author = {Nordlie, Eilen and Gewaltig, Marc Oliver and Plesser, Hans Ekkehard},
doi = {10.1371/journal.pcbi.1000456},
file = {:home/vbaker/neuron/lit/Towards Reproducible Descriptions of Neuronal Network Models.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {8},
pmid = {19662159},
title = {{Towards reproducible descriptions of neuronal network models}},
volume = {5},
year = {2009}
}
@article{Basawaraj2019,
abstract = {A generalization of active neural associative knowledge graphs (ANAKGs) to their minicolumn form is presented in this paper. Each minicolumn represents a single symbol, and the activation of an individual neuron in a minicolumn depends on the context of the activation of the presynaptic neuron. The implemented memory model combines the ANAKG associative spiking neuron idea with the idea of the hierarchical temporal memory. This new associative memory organization preserves all properties of ANAKG memories, such as storage of knowledge based on the association of spatiotemporal input sequences, self-organization, quick learning, and recall of the sequential memories, while increasing the recall quality and the memory capacity. The recall quality advantage of the new approach over ANAKG increases with the length of the recalled episodes and the number of neurons used in each minicolumn. We introduced a new distance measure to compare the recalled sequences and defined a recall quality to determine the memory capacity. Performed tests confirmed our claims. Additional tests were performed to illustrate the computational complexity and the efficiency of the developed approach.},
author = {Basawaraj and Starzyk, Janusz A. and Horzyk, Adrian},
doi = {10.1109/TNNLS.2019.2927106},
file = {:home/vbaker/neuron/lit/Episodic Memory in Minicolumn Associative Knowledge Graphs.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Associative episodic memory,distance measure,knowledge representation,minicolumn structure,recall quality},
number = {11},
pages = {3505--3516},
pmid = {31395554},
publisher = {IEEE},
title = {{Episodic Memory in Minicolumn Associative Knowledge Graphs}},
volume = {30},
year = {2019}
}
@article{buxhoeveden2002,
abstract = {The minicolumn is a continuing source of research and debate more than half a century after it was identified as a component of brain organization. The minicolumn is a sophisticated local network that contains within it the elements for redundancy and plasticity. Although it is sometimes compared to subcortical nuclei, the design of the minicolumn is a distinctive form of module that has evolved specifically in the neocortex. It unites the horizontal and vertical components of cortex within the same cortical space. Minicolumns are often considered highly repetitive, even clone-like, units. However, they display considerable heterogeneity between areas and species, perhaps even within a given macrocolumn. Despite a growing recognition of the anatomical basis of the cortical minicolumn, as well as its physiological properties, the potential of the minicolumn has not been exploited in fields such as comparative neuroanatomy, abnormalities of the brain and mind, and evolution.},
author = {Buxhoeveden, Daniel P. and Casanova, Manuel F.},
doi = {10.1093/brain/awf110},
file = {:home/vbaker/neuron/lit/bio/The minicolumn hypothesis in neuroscience.pdf:pdf},
issn = {00068950},
journal = {Brain},
keywords = {Columnar organization,Minicolumns,Modules},
number = {5},
pages = {935--951},
pmid = {11960884},
title = {{The minicolumn hypothesis in neuroscience}},
volume = {125},
year = {2002}
}
@article{DaCosta2010,
abstract = {The cortical column has been an invaluable concept to explain the functional organization of the neocortex. While this idea was born out of experiments that cleverly combined electrophysiological recordings with anatomy, no one has 'seen' the anatomy of a column. All we know is that when we record through the cortex of primates, ungulates, and carnivores in a trajectory perpendicular to its surface there is a remarkable constancy in the receptive field properties of the neurons regarding one set of stimulus features. There is no obvious morphological analog for this functional architecture, in fact much of the anatomical data seems to challenge it. Here we describe historically the origins of the concept of the cortical column and the struggles of the pioneers to define the columnar architecture. We suggest that in the concept of a 'canonical circuit' we may find the means to reconcile the structure of neocortex with its functional architecture. The canonical microcircuit respects the known connectivity of the neocortex, and it is fl exible enough to change transiently the architecture of its network in order to perform the required computations. {\textcopyright} 2010 da Costa and Martin.},
author = {da Costa, Nuno Ma{\c{c}}arico and Martin, Kevan A.C.},
doi = {10.3389/fnana.2010.00016},
file = {:home/vbaker/neuron/lit/bio/Whose cortical column would that be.pdf:pdf},
issn = {16625129},
journal = {Frontiers in Neuroanatomy},
keywords = {Bouton cluster,Canonical microcircuit,Cortical column,Daisy,Neuroanatomy},
number = {MAY},
pages = {1--10},
title = {{Whose cortical column would that be}},
volume = {4},
year = {2010}
}
@article{Ermentrout1979,
abstract = {A model for the interactions of cortical neurons is derived and analyzed. It is shown that small amplitude spatially inhomogeneous standing oscillations can bifurcate from the rest state. In a periodic domain, traveling wave trains exist. Stability of these patterns is discussed in terms of biological parameters. Homoclinic and heteroclinic orbits are demonstrated for the space-clamped system. {\textcopyright} 1979 Springer-Verlag.},
author = {Ermentrout, G. B. and Cowan, J. D.},
doi = {10.1007/BF00275728},
file = {:home/vbaker/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ermentrout, Cowan - 1979 - Temporal oscillations in neuronal nets.pdf:pdf},
issn = {14321416},
journal = {Journal of Mathematical Biology},
keywords = {Bifurcation theory,Neurobiology,Nonlinear integro-differential equations},
number = {3},
pages = {265--280},
pmid = {224126},
publisher = {Springer-Verlag},
title = {{Temporal oscillations in neuronal nets}},
url = {https://link.springer.com/article/10.1007/BF00275728},
volume = {7},
year = {1979}
}
@article{ermentrout2001,
abstract = {The theory of coupled phase oscillators provides a framework to understand the emergent properties of networks of neuronal oscillators. When the architecture of the network is dominated by short-range connections, the pattern of electrical output is predicted to correspond to traveling plane and rotating waves, in addition to synchronized output. We argue that this theory provides the foundation for understanding the traveling electrical waves that are observed across olfactory, visual, and visuomotor areas of cortex in a variety of species. The waves are typically present during periods outside of stimulation, while synchronous activity typically dominates in the presence of a strong stimulus. We suggest that the continuum of phase shifts during epochs with traveling waves provides a means to scan the incoming sensory stream for novel features. Experiments to test our theoretical approach are presented.},
author = {Ermentrout, G. Bard and Kleinfeld, David},
doi = {10.1016/S0896-6273(01)00178-7},
file = {:home/vbaker/neuron/lit/Traveling Electrical Waves in Cortex\: Insights from Phase Dynamics and Speculation on a Computational Role.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {33--44},
pmid = {11182079},
title = {{Traveling electrical waves in cortex: Insights from phase dynamics and speculation on a computational role}},
volume = {29},
year = {2001}
}
@article{Golomb1999,
abstract = {Propagation of discharges in cortical and thalamic systems, which is used as a probe for examining network circuitry, is studied by constructing a one-dimensional model of integrate-and-fire neurons that are coupled by excitatory synapses with delay. Each neuron fires only one spike. The velocity and stability of propagating continuous pulses are calculated analytically. Above a certain critical value of the constant delay, these pulses lose stability. Instead, lurching pulses propagate with discontinuous and periodic spatio-temporal characteristics. The parameter regime for which lurching occurs is stroGolomb1999ngly affected by the footprint (connectivity) shape; bistability may occur with a square footprint shape but not with an exponential footprint shape. For strong synaptic coupling, the velocity of both continuous and lurching pulses increases logarithmically with the synaptic coupling strength g(syn) for an exponential footprint shape, and it is bounded for a step footprint shape. We conclude that the differences in velocity and shape between the front of thalamic spindle waves in vitro and cortical paroxysmal discharges stem from their different effective delay; in thalamic networks, large effective delay between inhibitory neurons arises from their effective interaction via the excitatory cells which display postinhibitory rebound.},
author = {Golomb, David and Ermentrout, G. Bard},
doi = {10.1073/pnas.96.23.13480},
file = {:home/vbaker/neuron/lit/bio/Continuous and lurching traveling pulses in neuronal networks with delay and spatially decaying connectivity.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Discharge,Lurching,Neocortex,Pulse,Thalamus},
number = {23},
pages = {13480--13485},
pmid = {10557346},
title = {{Continuous and lurching traveling pulses in neuronal networks with delay and spatially decaying connectivity}},
volume = {96},
year = {1999}
}
@article{keane2015,
abstract = {Cortical neurons in vivo fire quite irregularly. Previous studies about the origin of such irregular neural dynamics have given rise to two major models: a balanced excitation and inhibition model, and a model of highly synchronized synaptic inputs. To elucidate the network mechanisms underlying synchronized synaptic inputs and account for irregular neural dynamics, we investigate a spatially extended, conductance-based spiking neural network model. We show that propagating wave patterns with complex dynamics emerge from the network model. These waves sweep past neurons, to which they provide highly synchronized synaptic inputs. On the other hand, these patterns only emerge from the network with balanced excitation and inhibition; our model therefore reconciles the two major models of irregular neural dynamics. We further demonstrate that the collective dynamics of propagating wave patterns provides a mechanistic explanation for a range of irregular neural dynamics, including the variability of spike timing, slow firing rate fluctuations, and correlated membrane potential fluctuations. In addition, in our model, the distributions of synaptic conductance and membrane potential are non-Gaussian, consistent with recent experimental data obtained using whole-cell recordings. Our work therefore relates the propagating waves that have been widely observed in the brain to irregular neural dynamics. These results demonstrate that neural firing activity, although appearing highly disordered at the single-neuron level, can form dynamical coherent structures, such as propagating waves at the population level.},
author = {Keane, Adam and Gong, Pulin},
doi = {10.1523/JNEUROSCI.1669-14.2015},
file = {:home/vbaker/neuron/lit/Propagating Wave Can Explain Irregular Neural Dynamics.pdf:pdf},
issn = {15292401},
journal = {Journal of Neuroscience},
keywords = {Balanced excitation and inhibition,Cerebral cortex,Computer simulation,Cross-correlation,Propagating waves,Synchrony},
number = {4},
pages = {1591--1605},
pmid = {25632135},
title = {{Propagating waves can explain irregular neural dynamics}},
volume = {35},
year = {2015}
}
@article{Wilson1973,
abstract = {It is proposed that distinct anatomical regions of cerebral cortex and of thalamic nuclei are functionally two-dimensional. On this view, the third (radial) dimension of cortical and thalamic structures is associated with a redundancy of circuits and functions so that reliable signal processing obtains in the presence of noisy or ambiguous stimuli. A mathematical model of simple cortical and thalamic nervous tissue is consequently developed, comprising two types of neurons (excitatory and inhibitory), homogeneously distributed in planar sheets, and interacting by way of recurrent lateral connexions. Following a discussion of certain anatomical and physiological restrictions on such interactions, numerical solutions of the relevant non-linear integro-differential equations are obtained. The results fall conveniently into three categories, each of which is postulated to correspond to a distinct type of tissue: sensory neo-cortex, archior prefrontal cortex, and thalamus. The different categories of solution are referred to as dynamical modes. The mode appropriate to thalamus involves a variety of non-linear oscillatory phenomena. That appropriate to archior prefrontal cortex is defined by the existence of spatially inhomogeneous stable steady states which retain contour information about prior stimuli. Finally, the mode appropriate to sensory neo-cortex involves active transient responses. It is shown that this particular mode reproduces some of the phenomenology of visual psychophysics, including spatial modulation transfer function determinations, certain metacontrast effects, and the spatial hysteresis phenomenon found in stereopsis. {\textcopyright} 1973 Springer-Verlag.},
author = {Wilson, H. R. and Cowan, J. D.},
doi = {10.1007/BF00288786},
file = {:home/vbaker/neuron/lit/A Mathematical Theory of the Functional Dynamics of Cortical and Thalamic Nervous Tissue.pdf:pdf},
issn = {03401200},
journal = {Kybernetik},
number = {2},
pages = {55--80},
pmid = {4767470},
title = {{A mathematical theory of the functional dynamics of cortical and thalamic nervous tissue}},
volume = {13},
year = {1973}
}
@article{lubernov2009,
abstract = {Theta oscillations clock hippocampal activity during awake behaviour and rapid eye movement (REM) sleep. These oscillations are prominent in the local field potential, and they also reflect the subthreshold membrane potential and strongly modulate the spiking of hippocampal neurons. The prevailing view is that theta oscillations are synchronized throughout the hippocampus, despite the lack of conclusive experimental evidence. In contrast, here we show that in freely behaving rats, theta oscillations in area CA1 are travelling waves that propagate roughly along the septotemporal axis of the hippocampus. Furthermore, we find that spiking in the CA1 pyramidal cell layer is modulated in a consistent travelling wave pattern. Our results demonstrate that theta oscillations pattern hippocampal activity not only in time, but also across anatomical space. The presence of travelling waves indicates that the instantaneous output of the hippocampus is topographically organized and represents a segment, rather than a point, of physical space. {\textcopyright} 2009 Macmillan Publishers Limited. All rights reserved.},
author = {Lubenov, Evgueniy V. and Siapas, Athanassios G.},
doi = {10.1038/nature08010},
file = {:home/vbaker/neuron/lit/bio/Hippocampal Theta Oscillations are Traveling Waves.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {7246},
pages = {534--539},
pmid = {19489117},
title = {{Hippocampal theta oscillations are travelling waves}},
volume = {459},
year = {2009}
}
@article{Rubino2006,
abstract = {High-frequency oscillations in the beta range (10-45 Hz) are most active in motor cortex during motor preparation and are postulated to reflect the steady postural state or global attentive state of the animal. By simultaneously recording multiple local field potential signals across the primary motor and dorsal premotor cortices of monkeys (Macaca mulatta) trained to perform an instructed-delay reaching task, we found that these oscillations propagated as waves across the surface of the motor cortex along dominant spatial axes characteristic of the local circuitry of the motor cortex. Moreover, we found that information about the visual target to be reached was encoded in terms of both latency and amplitude of evoked waves at a time when the field phase-locked with respect to the target onset. These findings suggest that high-frequency oscillations may subserve intra- and inter-cortical information transfer during movement preparation and execution. {\textcopyright} 2006 Nature Publishing Group.},
author = {Rubino, Doug and Robbins, Kay A. and Hatsopoulos, Nicholas G.},
doi = {10.1038/nn1802},
file = {:home/vbaker/neuron/lit/Propagating Waves Mediate Information Transfer in the Motor Cortex.pdf:pdf},
issn = {10976256},
journal = {Nature Neuroscience},
number = {12},
pages = {1549--1557},
pmid = {17115042},
title = {{Propagating waves mediate information transfer in the motor cortex}},
volume = {9},
year = {2006}
}
@article{Besserve2015,
abstract = {Distributed neural processing likely entails the capability of networks to reconfigure dynamically the directionality and strength of their functional connections. Yet, the neural mechanisms that may allow such dynamic routing of the information flow are not yet fully understood. We investigated the role of gamma band (50–80 Hz) oscillations in transient modulations of communication among neural populations by using measures of direction-specific causal information transfer. We found that the local phase of gamma-band rhythmic activity exerted a stimulus-modulated and spatially-asymmetric directed effect on the firing rate of spatially separated populations within the primary visual cortex. The relationships between gamma phases at different sites (phase shifts) could be described as a stimulus-modulated gamma-band wave propagating along the spatial directions with the largest information transfer. We observed transient stimulus-related changes in the spatial configuration of phases (compatible with changes in direction of gamma wave propagation) accompanied by a relative increase of the amount of information flowing along the instantaneous direction of the gamma wave. These effects were specific to the gamma-band and suggest that the time-varying relationships between gamma phases at different locations mark, and possibly causally mediate, the dynamic reconfiguration of functional connections.},
author = {Besserve, Michel and Lowe, Scott C. and Logothetis, Nikos K. and Sch{\"{o}}lkopf, Bernhard and Panzeri, Stefano},
doi = {10.1371/journal.pbio.1002257},
file = {:home/vbaker/neuron/lit/bio/Shifts of gamma phase across primary visual cortical sites reflect dynamic stimulus-modulated information transfer .pdf:pdf},
issn = {15457885},
journal = {PLoS Biology},
number = {9},
pages = {1--29},
pmid = {26394205},
title = {{Shifts of Gamma Phase across Primary Visual Cortical Sites Reflect Dynamic Stimulus-Modulated Information Transfer}},
volume = {13},
year = {2015}
}
@article{Muller2018,
abstract = {Multichannel recording technologies have revealed travelling waves of neural activity in multiple sensory, motor and cognitive systems. These waves can be spontaneously generated by recurrent circuits or evoked by external stimuli. They travel along brain networks at multiple scales, transiently modulating spiking and excitability as they pass. Here, we review recent experimental findings that have found evidence for travelling waves at single-area (mesoscopic) and whole-brain (macroscopic) scales. We place these findings in the context of the current theoretical understanding of wave generation and propagation in recurrent networks. During the large low-frequency rhythms of sleep or the relatively desynchronized state of the awake cortex, travelling waves may serve a variety of functions, from long-term memory consolidation to processing of dynamic visual stimuli. We explore new avenues for experimental and computational understanding of the role of spatiotemporal activity patterns in the cortex.},
author = {Muller, Lyle and Chavane, Fr{\'{e}}d{\'{e}}ric and Reynolds, John and Sejnowski, Terrence J.},
doi = {10.1038/nrn.2018.20},
file = {:home/vbaker/neuron/lit/Cortical Traveling Waves Mechanisms and Computational Principles.pdf:pdf},
issn = {14710048},
journal = {Nature Reviews Neuroscience},
number = {5},
pages = {255--268},
pmid = {29563572},
publisher = {Nature Publishing Group},
title = {{Cortical travelling waves: Mechanisms and computational principles}},
url = {http://dx.doi.org/10.1038/nrn.2018.20},
volume = {19},
year = {2018}
}
